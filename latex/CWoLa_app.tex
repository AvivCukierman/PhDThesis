%\section{List of MC samples}
%\label{sec:CWoLa:app:CWoLa:samples}

%Signal
%
%\begin{lstlisting}[breaklines=true,basicstyle=\footnotesize\ttfamily]
%mc16_13TeV.450288.Pythia8EvtGen_A14NNPDF23LO_Wprime_WZqqqq_M6000_m200_m200.deriv.DAOD_EXOT3.e7206_s3126_r9364_p3665
%mc16_13TeV.450284.Pythia8EvtGen_A14NNPDF23LO_Wprime_WZqqqq_M3000_m400_m400.deriv.DAOD_EXOT3.e7206_s3126_r9364_p3665
%mc16_13TeV.450287.Pythia8EvtGen_A14NNPDF23LO_Wprime_WZqqqq_M6000_m80_m400.deriv.DAOD_EXOT3.e7206_s3126_r9364_p3665
%mc16_13TeV.450281.Pythia8EvtGen_A14NNPDF23LO_Wprime_WZqqqq_M3000_m80_m400.deriv.DAOD_EXOT3.e7206_s3126_r9364_p3665
%mc16_13TeV.450286.Pythia8EvtGen_A14NNPDF23LO_Wprime_WZqqqq_M6000_m80_m200.deriv.DAOD_EXOT3.e7206_s3126_r9364_p3665
%mc16_13TeV.450290.Pythia8EvtGen_A14NNPDF23LO_Wprime_WZqqqq_M6000_m400_m400.deriv.DAOD_EXOT3.e7206_s3126_r9364_p3665
%mc16_13TeV.450283.Pythia8EvtGen_A14NNPDF23LO_Wprime_WZqqqq_M3000_m200_m400.deriv.DAOD_EXOT3.e7206_s3126_r9364_p3665
%mc16_13TeV.450282.Pythia8EvtGen_A14NNPDF23LO_Wprime_WZqqqq_M3000_m200_m200.deriv.DAOD_EXOT3.e7206_s3126_r9364_p3665
%mc16_13TeV.450285.Pythia8EvtGen_A14NNPDF23LO_Wprime_WZqqqq_M6000_m80_m80.deriv.DAOD_EXOT3.e7206_s3126_r9364_p3665
%mc16_13TeV.450280.Pythia8EvtGen_A14NNPDF23LO_Wprime_WZqqqq_M3000_m80_m200.deriv.DAOD_EXOT3.e7206_s3126_r9364_p3665
%mc16_13TeV.450289.Pythia8EvtGen_A14NNPDF23LO_Wprime_WZqqqq_M6000_m200_m400.deriv.DAOD_EXOT3.e7206_s3126_r9364_p3665
%mc16_13TeV.450279.Pythia8EvtGen_A14NNPDF23LO_Wprime_WZqqqq_M3000_m80_m80.deriv.DAOD_EXOT3.e7206_s3126_r9364_p3665
%\end{lstlisting}

%\section{Neural Network Steps}
%\label{sec:CWoLa:app:CWoLa:NNsteps}

%\section{Background-only Neural Network Output}
%\label{sec:CWoLa:app:CWoLa:NNout_bkg}
%The regions that the neural network tags as ``signal-like", in the absence of any true signal, are shown in Figure~\ref{fig:CWoLa:NNout_sigRx}.
%\begin{figure}[htbp]
%  \centering 
%  \subfloat[]{\includegraphics[width=0.3\textwidth]{figures_CWoLa/{NNout_sigR1_12.31.18}.png}}
%  \subfloat[]{\includegraphics[width=0.3\textwidth]{figures_CWoLa/{NNout_sigR2_12.31.18}.png}}
%  \subfloat[]{\includegraphics[width=0.3\textwidth]{figures_CWoLa/{NNout_sigR3_12.31.18}.png}}\\
%  \subfloat[]{\includegraphics[width=0.3\textwidth]{figures_CWoLa/{NNout_sigR4_12.31.18}.png}}
%  \subfloat[]{\includegraphics[width=0.3\textwidth]{figures_CWoLa/{NNout_sigR5_12.31.18}.png}}
%  \subfloat[]{\includegraphics[width=0.3\textwidth]{figures_CWoLa/{NNout_sigR6_12.31.18}.png}}\\
%  \subfloat[]{\includegraphics[width=0.3\textwidth]{figures_CWoLa/{NNout_sigR7_12.31.18}.png}}
%  \subfloat[]{\includegraphics[width=0.3\textwidth]{figures_CWoLa/{NNout_sigR8_12.31.18}.png}}
%  \subfloat[]{\includegraphics[width=0.3\textwidth]{figures_CWoLa/{NNout_sigR9_12.31.18}.png}}\\
%  \caption{Neural network output in the absence of any true signal for signal regions (a) 1; (b) 2; (c) 3; (d) 4; (e) 5; (f) 6; (g) 7; (h) 8; (i) 9. Blue indicates more signal-like.}
%\label{fig:CWoLa:NNout_sigRx}
%\end{figure}

%\begin{figure}[htbp]
%  \centering 
%  \subfloat[]{\includegraphics[width=0.3\textwidth]{figures_CWoLa/{NNout_q99_sigR1_12.31.18_scatter}.png}}
%  \subfloat[]{\includegraphics[width=0.3\textwidth]{figures_CWoLa/{NNout_q99_sigR2_12.31.18_scatter}.png}}
%  \subfloat[]{\includegraphics[width=0.3\textwidth]{figures_CWoLa/{NNout_q99_sigR3_12.31.18_scatter}.png}}\\
%  \subfloat[]{\includegraphics[width=0.3\textwidth]{figures_CWoLa/{NNout_q99_sigR4_12.31.18_scatter}.png}}
%  \subfloat[]{\includegraphics[width=0.3\textwidth]{figures_CWoLa/{NNout_q99_sigR5_12.31.18_scatter}.png}}
%  \subfloat[]{\includegraphics[width=0.3\textwidth]{figures_CWoLa/{NNout_q99_sigR6_12.31.18_scatter}.png}}\\
%  \subfloat[]{\includegraphics[width=0.3\textwidth]{figures_CWoLa/{NNout_q99_sigR7_12.31.18_scatter}.png}}
%  \subfloat[]{\includegraphics[width=0.3\textwidth]{figures_CWoLa/{NNout_q99_sigR8_12.31.18_scatter}.png}}
%  \subfloat[]{\includegraphics[width=0.3\textwidth]{figures_CWoLa/{NNout_q99_sigR9_12.31.18_scatter}.png}}\\
%  \caption{Scatter plot of the events remaining after a $\epsilon=0.01$ neural network cut, in the absence of any true signal, in signal regions (a) 1; (b) 2; (c) 3; (d) 4; (e) 5; (f) 6; (g) 7; (h) 8; (i) 9.}
%\label{fig:CWoLa:NNout_q99_sigRx}
%\end{figure}

\section{Alternate Ideas for Validation}
\label{app:CWoLa:validation_alternate}
Section~\ref{sec:CWoLa:blinding} discusses the difficulties present in this analysis for constructing a validation sample with low signal efficiency to test the analysis pipeline.
The primary validation sample used in this analysis is formed by inverting the delta rapidity cut.
Some other ideas for forming a validation sample are below, which could be useful for a future analysis based on classification without labels, e.g. one that does not want to impose a delta rapidity cut or one targeting a different topology entirely.

\subsection{Swapped Dataset}
One possibility for a validation sample which is derived from data, and still retains the property that the signal contamination is low, is called the \textit{jet swapped} dataset.
In this dataset, leading and subleading jets are swapped between random pairs of events.
It is expected that this sample has low signal contamination, because it is unlikely that two random events chosen from the original sample will both be signal events.
In particular, suppose that there is some number of signal, $S$, and some number of background, $B$, in the original sample with no cuts.
We can suppose that the signal fraction $\frac{S}{B} = p\ll1$, due to existing limits from the inclusive dijet search~\cite{Aad:2019hjw} (note that the limits from previous searches set a stronger bound, that the significance $\frac{S}{\sqrt{B}}=p\sqrt{B} \lesssim 1$).
Then the signal contamination in the swapped dataset is expected to be on the order of $p^2 \ll p$ (and therefore with significance $p^2\sqrt{B} \ll 1$).

The $m_{JJ}$ distribution in the swapped dataset is different than in the original sample, and some correlations between the ensemble of jet features and the $m_{JJ}$ value will not be preserved.
However, any correlations between the individual jet features and the jet $p_T$ will be preserved, and thus some significant part of the correlations between the individual jet features and the $m_{JJ}$ value.
The swapped dataset therefore serves as an entirely data-derived reasonable proxy for the background spectrum of the features and of $m_{JJ}$, and can be used as a validation region for testing the validity of the background shape fit, for demonstrating that the learned features do not sculpt the $m_{JJ}$ distribution and therefore violate Assumption~\ref{ass2}, and for demonstrating the sensitivity of the method to (unswapped) injected signal.
%In particular, if the learned cuts sculpted the $m_{JJ}$ spectrum based on the individual jet features, the jet swapped dataset would also observe this effect.

\subsection{Anti-tagged Dataset}
After learning the neural network scores to distinguish events in the signal region from events in the sideband regions, cuts are placed at some efficiency $\epsilon < 1$ in order to find the most signal-like events.
That is to say, every event $i$ has a score $0\le S_i \le 1$ based on the neural network output, with larger $S_i$ indicating an event more signal-like, and moreover the scores are scaled such that a cut $S_i>1-\epsilon$ has efficiency exactly $\epsilon$ in the signal region bin.

There is a concept of anti-tagging in this framework: by applying a cut $S_i<\epsilon$, the $\epsilon$ fraction of events that are the least signal-like are chosen.
However, this anti-tagged dataset may still be contaminated by signal, in particular if the true signal is actually mostly in the sideband region rather than the signal region i.e. Case~\ref{case2}; in this case the scores $S_i$ are signal anti-taggers in the first place, and so the anti-tagged dataset is in fact anti-anti-tagging signal, i.e. positively tagging signal.

\subsection{Median Dataset}
Another possibility is to consider the \textit{median dataset}, where the cut that is placed is $|S_i-0.5|<\frac{\epsilon}{2}$.
These are the set of events that the neural network has decided it is agnostic about being in the signal region or the sideband regions; it is therefore expected that this dataset has little signal contamination, because regardless of whether the true signal was in the signal or sideband regions, it would not end up with this median score.
It is not expected that the $m_{JJ}$ distribution will be exactly the same in the median dataset as in the signal-tagged dataset, even in the case there is no true signal, since there are some residual correlations between the features and $m_{JJ}$.
However, the median dataset can be used to test the validity of the background shape fit, and for looking at jet kinematics in a blinded way.

\section{Analysis Software}
\label{app:CWoLa:software}

The \href{https://gitlab.cern.ch/acukierm/mc16-xAOD-ntuple-maker}{mc16-xAOD-ntuple-maker} package is used to create ntuples used for the analysis.
The machine learning code can be found in \href{https://gitlab.cern.ch/cwola-hunting/cwola-hunting-learning}{cwola-hunting-learning} package.
%The final fit was performed using the \href{https://gitlab.cern.ch/atlas-phys/exot/dbl/ResonanceFinder}{ResonanceFinder} package.   Our modifications to this package can be found \href{https://gitlab.cern.ch/cwola-hunting/fitting/tree/minimal}{here}.

\section{Fitting Software}
\label{app:CWoLa:fitting_software}
The statistical analysis uses the \href{https://gitlab.cern.ch/atlas-phys/exot/dbl/ResonanceFinder}{\texttt{ResonanceFinder}} package from the DBL group.
This code is based on RooFit~\cite{Verkerke:2003ir}, RooStats~\cite{Moneta:2010pm}, and HistFactory~\cite{Cranmer:1456844}.
Significant modifications for the background fitting were made for this analysis, which can be found \href{https://gitlab.cern.ch/cwola-hunting/fitting/tree/minimal}{here}.


\section{Bin Offset Test}
\label{app:CWoLa:binoffset}
A study of the effect of the bin positioning relative to the signal center $m_A$ is shown in Figure~\ref{fig:CWoLa:NN_binoffset}.
A fixed signal is injected with $m_A=3000$ GeV, so that the $m_{JJ}$ distribution of the signal lies mostly in signal region 5.
For this study only, the signal region bins are shifted in units of $0.25$ the current bin size, so that after $4$ shifts the bins are exactly the same as before with the numbering changed by $1$.
The NN efficiency on the signal at $\epsilon=0.1$ is shown as a function of the center of signal region 5, when the signal region used for training is 4, 5, and 6.
It can be seen that, regardless of where the bin definitions are, there is some signal region for which the NN efficiency is high ($>0.4$).
Importantly, the NN maintains very high signal efficiency ($>0.8$) in 3 out of the 4 bin positions, and dips lower in only the final 1 out of 4 positions.
This indicates that if the signal $m_A$ lies in roughly $75\%$ of the $m_{JJ}$ kinematic space, the NN performance is unaffected, while in the remaining $25\%$ of the space the NN can still learn to tag the signal albeit at lower efficiency; regardless, CWoLa is sensitive to these new signals.

\begin{figure}[h!]
\centering
\subfloat[]{\includegraphics[width=0.45\textwidth]{figures_CWoLa/{NN_binoffset_q90_sigR456_Wprime_WZqqqq_M3000_m200_m200_patience100_1.14.20}.pdf}}
\caption{The efficiency of the NN on the signal ($m_A,m_B,m_C=(3000,200,200)$ GeV) at cut $\epsilon=0.1$ at different values of the center of signal region 5.
The efficiency of the NN is shown when training on signal region 4 (in red); 5 (in blue); and 6 (in green).
The distribution of $m_{JJ}$ in the signal is also shown (in orange) for reference.}
\label{fig:CWoLa:NN_binoffset}
\end{figure}


%\section{Validation Data: No Signal NN Output}
%\label{app:CWoLa:inverted:NNout}
%\begin{figure}[h!]
%\centering
%\subfloat[]{\includegraphics[width=0.45\textwidth]{figures_CWoLa/{NNoutcontrast_sigR6_patience100_yinvertresample_11.2.19}.pdf}}
%subfloat[]{\includegraphics[width=0.45\textwidth]{figures_CWoLa/{NNoutcontrast_sigR7_patience100_yinvertresample_11.2.19}.pdf}}\\
%\subfloat[]{\includegraphics[width=0.45\textwidth]{figures_CWoLa/{NNoutcontrast_sigR8_patience100_yinvertresample_11.2.19}.pdf}}
%\subfloat[]{\includegraphics[width=0.45\textwidth]{figures_CWoLa/{NNoutcontrast_sigR9_patience100_yinvertresample_11.2.19}.pdf}}\\
%\caption{The output of the neural network when there is no injected signal, in signal region (a) 6; (b) 7; (c) 8; (d) 9. Note that these are data and not simulation, using the inverted rapidity cut data selection.}
%\label{fig:CWoLa:inverted:NNsensitivity:nosignal_app}
%\end{figure}

\FloatBarrier
\section{Validation Analysis: No Signal Fits}
\label{app:CWoLa:inverted:fit_nosignal}
The fit on the validation data with no signal injected is shown for signal region 6 (Figure~\ref{fig:CWoLa:inverted:fit_sigR6_nosignal}); signal region 7 (Figure~\ref{fig:CWoLa:inverted:fit_sigR7_nosignal}); signal region 8 (Figure~\ref{fig:CWoLa:inverted:fit_sigR8_nosignal}); and signal region 9 (Figure~\ref{fig:CWoLa:inverted:fit_sigR9_nosignal}).
These fits generally indicate problems with the $\epsilon=1.0$ and $\epsilon=0.25$ fits, especially at lower masses, which motivates the decision to limit the analysis to only $\epsilon=0.1$ and $\epsilon=0.01$ for the full unblinded analysis.
\begin{figure}[h!]
\centering
\subfloat[]{\includegraphics[width=0.45\textwidth]{figures_CWoLa/{sigR6_patience100_yinvertresample_11.2.19_SWiFT_all}.pdf}}
\subfloat[]{\includegraphics[width=0.45\textwidth]{figures_CWoLa/{q75_sigR6_patience100_yinvertresample_11.2.19_SWiFT_all}.pdf}}\\
\subfloat[]{\includegraphics[width=0.45\textwidth]{figures_CWoLa/{q90_sigR6_patience100_yinvertresample_11.2.19_SWiFT_all}.pdf}}
\subfloat[]{\includegraphics[width=0.45\textwidth]{figures_CWoLa/{q99_sigR6_patience100_yinvertresample_11.2.19_SWiFT_all}.pdf}}
\caption{The background fit when there is no injected signal, in signal region 6, for various efficiency points $\epsilon$. Note that these are data and not simulation, using the inverted rapidity cut data selection.}
\label{fig:CWoLa:inverted:fit_sigR6_nosignal}
\end{figure}

\begin{figure}[h!]
\centering
\subfloat[]{\includegraphics[width=0.45\textwidth]{figures_CWoLa/{sigR7_patience100_yinvertresample_11.2.19_SWiFT_all}.pdf}}
\subfloat[]{\includegraphics[width=0.45\textwidth]{figures_CWoLa/{q75_sigR7_patience100_yinvertresample_11.2.19_SWiFT_all}.pdf}}\\
\subfloat[]{\includegraphics[width=0.45\textwidth]{figures_CWoLa/{q90_sigR7_patience100_yinvertresample_11.2.19_SWiFT_all}.pdf}}
\subfloat[]{\includegraphics[width=0.45\textwidth]{figures_CWoLa/{q99_sigR7_patience100_yinvertresample_11.2.19_SWiFT_all}.pdf}}
\caption{The background fit when there is no injected signal, in signal region 7, for various efficiency points $\epsilon$. Note that these are data and not simulation, using the inverted rapidity cut data selection.}
\label{fig:CWoLa:inverted:fit_sigR7_nosignal}
\end{figure}

\begin{figure}[h!]
\centering
\subfloat[]{\includegraphics[width=0.45\textwidth]{figures_CWoLa/{sigR8_patience100_yinvertresample_11.2.19_SWiFT_all}.pdf}}
\subfloat[]{\includegraphics[width=0.45\textwidth]{figures_CWoLa/{q75_sigR8_patience100_yinvertresample_11.2.19_SWiFT_all}.pdf}}\\
\subfloat[]{\includegraphics[width=0.45\textwidth]{figures_CWoLa/{q90_sigR8_patience100_yinvertresample_11.2.19_SWiFT_all}.pdf}}
\subfloat[]{\includegraphics[width=0.45\textwidth]{figures_CWoLa/{q99_sigR8_patience100_yinvertresample_11.2.19_SWiFT_all}.pdf}}
\caption{The background fit when there is no injected signal, in signal region 8, for various efficiency points $\epsilon$. Note that these are data and not simulation, using the inverted rapidity cut data selection.}
\label{fig:CWoLa:inverted:fit_sigR8_nosignal}
\end{figure}

\begin{figure}[h!]
\centering
\subfloat[]{\includegraphics[width=0.45\textwidth]{figures_CWoLa/{sigR9_patience100_yinvertresample_11.2.19_SWiFT_all}.pdf}}
\subfloat[]{\includegraphics[width=0.45\textwidth]{figures_CWoLa/{q75_sigR9_patience100_yinvertresample_11.2.19_SWiFT_all}.pdf}}\\
\subfloat[]{\includegraphics[width=0.45\textwidth]{figures_CWoLa/{q90_sigR9_patience100_yinvertresample_11.2.19_SWiFT_all}.pdf}}
\subfloat[]{\includegraphics[width=0.45\textwidth]{figures_CWoLa/{q99_sigR9_patience100_yinvertresample_11.2.19_SWiFT_all}.pdf}}
\caption{The background fit when there is no injected signal, in signal region 9, for various efficiency points $\epsilon$. Note that these are data and not simulation, using the inverted rapidity cut data selection.}
\label{fig:CWoLa:inverted:fit_sigR9_nosignal}
\end{figure}

%\section{Validation Data: Injected Signal Fits}
%\label{app:CWoLa:inverted:fit_signal}

\FloatBarrier
\section{Unblinded Analysis: Signal Injection Tests}
\label{app:CWoLa:signalinjection}

The effect of an injected signal on the fit is studied.
Figure~\ref{fig:CWoLa:signalinjection} shows the dependence of the maximum likelihood signal strength $\hat{\mu}$ on the injected signal strength $\mu=\mathcal{L}\times\sigma$, where $\mathcal{L}$ is the data luminosity and $\sigma$ is the cross section for the production of the given signal.
Also indicated is the final 95\% CL exclusion limit on the given signal.
It can be seen that the fitted signal strength is not consistent with the injected signal strength for values below the 95\% CL exclusion limit; above that value there is some bias towards smaller values due to the fit process outlined in Section~\ref{sec:CWoLa:unblinded:fitting}.

\begin{figure}[h!]
\centering
\subfloat[]{\includegraphics[width=0.33\textwidth]{figures_CWoLa/{inj_closure_M3000_m200_m200_q90_3000}.pdf}}
\subfloat[]{\includegraphics[width=0.33\textwidth]{figures_CWoLa/{inj_closure_M3000_m200_m400_q90_3000}.pdf}}
\subfloat[]{\includegraphics[width=0.33\textwidth]{figures_CWoLa/{inj_closure_M3000_m400_m400_q90_3000}.pdf}}\\
\subfloat[]{\includegraphics[width=0.33\textwidth]{figures_CWoLa/{inj_closure_M5000_m200_m200_q90_5000}.pdf}}
\subfloat[]{\includegraphics[width=0.33\textwidth]{figures_CWoLa/{inj_closure_M5000_m200_m400_q90_5000}.pdf}}
\subfloat[]{\includegraphics[width=0.33\textwidth]{figures_CWoLa/{inj_closure_M5000_m400_m400_q90_5000}.pdf}}
\caption{The dependence of the fitted signal strength $\hat{\mu}$ on the injected signal strength $\mu$ with a NN cut at efficiency $\epsilon=0.1$ trained on (a,b,c) signal region 5 and (d,e,f) signal region 8 for a signal with $m_A,m_B,m_C$ equal to (a) (3000,200,200); (b) (3000,400,200); (c) (3000,400,400); (d) (5000,200,200); (e) (5000,400,200); and (f) (5000,400,400) GeV. Also shown is the 95\% CL exclusion limit for the given signal.}
\label{fig:CWoLa:signalinjection}
\end{figure}

\FloatBarrier
\section{Unblinded Analysis: Neural Network Dependence on $\mu$}
\label{app:CWoLa:unblinded:NNeff_mu}
The NN efficiency on the given signals as a function of $\mu$ is given in Figure~\ref{fig:CWoLa:unblinded:NNeff_mu_3000} for signals with $m_A=3000$ GeV and in Figure~\ref{fig:CWoLa:unblinded:NNeff_mu_5000} for signals with $m_A=5000$ GeV.
The NN output for each of the $5$ different random samplings of the signal is included.
The NN with the median efficiency on the signal is also indicated; note that this does not necessarily correspond to the NN that gives rise to the median expected limit, because the shape of the background may change, and so this is only indicated as an aesthetic choice.
The envelope of the outputs across the different random samplings tends to be small when the efficiency is very high or very low, while the envelope widens at the $\mu$ values where the efficiency is middling; these are exactly the transition regions where the NN can find the signal but does not always.
The median NN tends to be smoothly rising with $\mu$, while single samplings from the envelope may not be; thus, the choice to run the analysis with different random samplings serves as a smoothing procedure.
For $m_A=5000$ GeV, for the best-performing signals at high $m_B,m_C$, the NN efficiency actually goes down with increasing $\mu$.
This is simply due to the fact that at these values of $\mu$ the amount of signal is comparable to the $10\%$ or $1\%$ of the signal plus background remaining after the NN tagging, so that it is mathematically impossible to have a higher efficiency on the signal and retain the overall efficiency on all the events in the signal region.

\begin{figure}[h!]
\centering
\subfloat[]{\includegraphics[width=0.25\textwidth]{figures_CWoLa/{NNeff_mu_q90_sigR5_Wprime_WZqqqq_M3000_m80_m80_patience100_1.14.20}.pdf}}
\subfloat[]{\includegraphics[width=0.25\textwidth]{figures_CWoLa/{NNeff_mu_q99_sigR5_Wprime_WZqqqq_M3000_m80_m80_patience100_1.14.20}.pdf}}
\subfloat[]{\includegraphics[width=0.25\textwidth]{figures_CWoLa/{NNeff_mu_q90_sigR5_Wprime_WZqqqq_M3000_m80_m200_patience100_1.14.20}.pdf}}
\subfloat[]{\includegraphics[width=0.25\textwidth]{figures_CWoLa/{NNeff_mu_q99_sigR5_Wprime_WZqqqq_M3000_m80_m200_patience100_1.14.20}.pdf}}\\
\subfloat[]{\includegraphics[width=0.25\textwidth]{figures_CWoLa/{NNeff_mu_q90_sigR5_Wprime_WZqqqq_M3000_m80_m400_patience100_1.14.20}.pdf}}
\subfloat[]{\includegraphics[width=0.25\textwidth]{figures_CWoLa/{NNeff_mu_q99_sigR5_Wprime_WZqqqq_M3000_m80_m400_patience100_1.14.20}.pdf}}
\subfloat[]{\includegraphics[width=0.25\textwidth]{figures_CWoLa/{NNeff_mu_q90_sigR5_Wprime_WZqqqq_M3000_m200_m200_patience100_1.14.20}.pdf}}
\subfloat[]{\includegraphics[width=0.25\textwidth]{figures_CWoLa/{NNeff_mu_q99_sigR5_Wprime_WZqqqq_M3000_m200_m200_patience100_1.14.20}.pdf}}\\
\subfloat[]{\includegraphics[width=0.25\textwidth]{figures_CWoLa/{NNeff_mu_q90_sigR5_Wprime_WZqqqq_M3000_m200_m400_patience100_1.14.20}.pdf}}
\subfloat[]{\includegraphics[width=0.25\textwidth]{figures_CWoLa/{NNeff_mu_q99_sigR5_Wprime_WZqqqq_M3000_m200_m400_patience100_1.14.20}.pdf}}
\subfloat[]{\includegraphics[width=0.25\textwidth]{figures_CWoLa/{NNeff_mu_q90_sigR5_Wprime_WZqqqq_M3000_m400_m400_patience100_1.14.20}.pdf}}
\subfloat[]{\includegraphics[width=0.25\textwidth]{figures_CWoLa/{NNeff_mu_q99_sigR5_Wprime_WZqqqq_M3000_m400_m400_patience100_1.14.20}.pdf}}\\
\caption{The efficiency of the NN as a function of $\mu$ on the injected signal at $m_A=3000$, in signal region 5, for (a,c,e,g,i,k) $\epsilon=0.1$ and (b,d,f,h,j,l) $\epsilon=0.01$. 
  There are 5 lines corresponding to the $5$ different random samplings of the signal in the training of the NN; the network with the median efficiciency is also marked.
  Each signal is labeled by ($m_B,m_C$) in \GeV. (a,b) (80,80); (c,d) (80,200); (e,f) (80,400); (g,h) (200,200); (i,j) (200,400); (k,l) (400,400).
}
\label{fig:CWoLa:unblinded:NNeff_mu_3000}
\end{figure}

\begin{figure}[h!]
\centering
\subfloat[]{\includegraphics[width=0.25\textwidth]{figures_CWoLa/{NNeff_mu_q90_sigR8_Wprime_WZqqqq_M5000_m80_m80_patience100_1.14.20}.pdf}}
\subfloat[]{\includegraphics[width=0.25\textwidth]{figures_CWoLa/{NNeff_mu_q99_sigR8_Wprime_WZqqqq_M5000_m80_m80_patience100_1.14.20}.pdf}}
\subfloat[]{\includegraphics[width=0.25\textwidth]{figures_CWoLa/{NNeff_mu_q90_sigR8_Wprime_WZqqqq_M5000_m80_m200_patience100_1.14.20}.pdf}}
\subfloat[]{\includegraphics[width=0.25\textwidth]{figures_CWoLa/{NNeff_mu_q99_sigR8_Wprime_WZqqqq_M5000_m80_m200_patience100_1.14.20}.pdf}}\\
\subfloat[]{\includegraphics[width=0.25\textwidth]{figures_CWoLa/{NNeff_mu_q90_sigR8_Wprime_WZqqqq_M5000_m80_m400_patience100_1.14.20}.pdf}}
\subfloat[]{\includegraphics[width=0.25\textwidth]{figures_CWoLa/{NNeff_mu_q99_sigR8_Wprime_WZqqqq_M5000_m80_m400_patience100_1.14.20}.pdf}}
\subfloat[]{\includegraphics[width=0.25\textwidth]{figures_CWoLa/{NNeff_mu_q90_sigR8_Wprime_WZqqqq_M5000_m200_m200_patience100_1.14.20}.pdf}}
\subfloat[]{\includegraphics[width=0.25\textwidth]{figures_CWoLa/{NNeff_mu_q99_sigR8_Wprime_WZqqqq_M5000_m200_m200_patience100_1.14.20}.pdf}}\\
\subfloat[]{\includegraphics[width=0.25\textwidth]{figures_CWoLa/{NNeff_mu_q90_sigR8_Wprime_WZqqqq_M5000_m200_m400_patience100_1.14.20}.pdf}}
\subfloat[]{\includegraphics[width=0.25\textwidth]{figures_CWoLa/{NNeff_mu_q99_sigR8_Wprime_WZqqqq_M5000_m200_m400_patience100_1.14.20}.pdf}}
\subfloat[]{\includegraphics[width=0.25\textwidth]{figures_CWoLa/{NNeff_mu_q90_sigR8_Wprime_WZqqqq_M5000_m400_m400_patience100_1.14.20}.pdf}}
\subfloat[]{\includegraphics[width=0.25\textwidth]{figures_CWoLa/{NNeff_mu_q99_sigR8_Wprime_WZqqqq_M5000_m400_m400_patience100_1.14.20}.pdf}}\\
\caption{The efficiency of the NN as a function of $\mu$ on the injected signal at $m_A=5000$, in signal region 8, for (a,c,e,g,i,k) $\epsilon=0.1$ and (b,d,f,h,j,l) $\epsilon=0.01$. 
  There are 5 lines corresponding to the $5$ different random samplings of the signal in the training of the NN; the network with the median efficiciency is also marked.
  Each signal is labeled by ($m_B,m_C$) in \GeV. (a,b) (80,80); (c,d) (80,200); (e,f) (80,400); (g,h) (200,200); (i,j) (200,400); (k,l) (400,400).
}
\label{fig:CWoLa:unblinded:NNeff_mu_5000}
\end{figure}

\FloatBarrier
\section{Unblinded Analysis: Fit Correction}
\label{app:CWoLa:fit_closure}
It is found that the distribution of significances of data with respect to the background fit both has a global (negative) offset and also has some dependence on $m_{JJ}$.
This is verified in the validation (inverted rapidity cut) data, as can be seen in Figure~\ref{fig:CWoLa:inverted:significance_dist}.
\begin{figure}[h!]
\centering
\subfloat[]{\includegraphics[width=0.45\textwidth]{figures_CWoLa/{pulls_patience100_yinvertresample}.pdf}\label{fig:CWoLa:inverted:significance_offset}}
\subfloat[]{\includegraphics[width=0.45\textwidth]{figures_CWoLa/{pulls_mjj_patience100_yinvertresample}.pdf}\label{fig:CWoLa:inverted:significance_mjj_fit}}\\
\subfloat[]{\includegraphics[width=0.45\textwidth]{figures_CWoLa/{pulls_patience100_yinvertresample_UA2}.pdf}}
\subfloat[]{\includegraphics[width=0.45\textwidth]{figures_CWoLa/{pulls_mjj_patience100_yinvertresample_UA2}.pdf}}
\caption{Distribution of significances in validation (inverted rapidity cut) data.
  (a,c) Overall distribution. The green dashed line shows the mean significance and the green dotted lines show the standard error on the estimate of the mean. The $t$-stat of this estimate is shown on the plot as well.
  (b,d) Dependence on $m_{JJ}$. The dots show individual observations across the $6$ signal region bins at each value of $m_{JJ}$ included in the fits. The red points with error bars bin these values and show the average in order to reduce the noise. The green dashed line shows the line of best fit, and the green dotted lines show the standard error on the fit. The $t$-stat associated with the estimate of the slope of the fit line is shown on the plot as well.
  (a,b) Using the nominal fit function (\ref{fitstep:1} and \ref{fitstep:2});
  (c,d) Using the UA2 fit function (\ref{fitstep:3}).
}
\label{fig:CWoLa:inverted:significance_dist}
\end{figure}
Only bins with fit values greater than $10$ are included, as the distribution of significances is not expected to be Normal for bins with low counts; see~\cite{Nachman:2012zf}.
The effect is measured both when restricting the fit to just the nominal fit functions (\ref{fitstep:1} and \ref{fitstep:2}) and when restricting the fit to just the UA2 fit function (\ref{fitstep:3}).

Some key statistics of the distribution of significances when using the nominal fit functions are given in Table~\ref{tab:validation:significance_dist}.
\begin{table}[htb]
  \centering
  \caption{Key statistics of distribution of significances in validation selection data.}
  \label{tab:validation:significance_dist}
  \begin{tabular}{c c}
    \hline
Statistic & Value   \\ \hline
Mean & -0.16 \\
Std. Dev. & 1.02 \\
Mean Std. Err. & 0.06 \\
$m_{JJ}$ Fit Slope& -0.20~\TeV$^{-1}$  \\
$m_{JJ}$ Fit Slope Std. Err.& 0.06~\TeV$^{-1}$  \\
$m_{JJ}$ Fit Intercept& 0.49 \\
    \hline
  \end{tabular}
\end{table}
The fit values are used to correct the background fit bin-by-bin given the $m_{JJ}$ value in that bin; i.e., the correction is exactly the green dashed line in Figure~\ref{fig:CWoLa:inverted:significance_mjj_fit}.
Since there is uncertainty on the estimate of the offset and mean from the validation dataset, and in addition an uncertainty on whether the fit derived in the validation dataset applies to the signal selection dataset, an uncertainty is applied on the offset and the slope independently according to the standard error of the estimate.

The question of how exactly to apply this correction is non-trivial.
The correction is derived on the significance of the data with respect to the background fit in the validation selection data, but it would be improper in general to set the median background fit value to the value that changes the significance by the correction amount, since then this correction would depend on the observed data in each bin.
Instead, the correction is applied to change the (approximate) median of the expected distribution of event counts under the Poisson hypothesis to have a significance of the corrected value.
In other words, given the background fit value $E_i$ and correction value $c$, the new fit value $E_i'$ is given by:
\begin{align}
  S(E_i',\left\lfloor E_i+1 \right\rfloor ) = S(E_i,\left\lfloor E_i+1 \right\rfloor)-c,
  \label{eqn:CWoLa:significance_corr}
\end{align}
where $S(E_i,O_i)$ is the significance as defined in Equation~\ref{eqn:CWoLa:significance_def}.
For the variations of the offset and the slope according to their uncertainties, new values of $E_i'$ are calculated according to the up and down variations of each.
The additional uncertainty on the background fit value $E_i'$ is given as the sum in quadrature of the differences due to these new values.

After applying this correction, the distribution of significances in the validation selection (inverted rapidity cut) data is shown in Figure~\ref{fig:CWoLa:inverted:significance_dist_corr}.
After the correction, the distribution of significances is consistent with mean $0$ across the entire range, indicating that the correction (Equation~\ref{eqn:CWoLa:significance_corr}) is working as intended.
\begin{figure}[h!]
\centering
\subfloat[]{\includegraphics[width=0.45\textwidth]{figures_CWoLa/{pulls_corr_patience100_yinvertresample}.pdf}}
\subfloat[]{\includegraphics[width=0.45\textwidth]{figures_CWoLa/{pulls_mjj_corr_vars_patience100_yinvertresample}.pdf}}\\
\caption{Distribution of significances in validation (inverted rapidity cut) data after applying the background fit correction.
  (a) Overall distribution, showing the up and down variations of the offset term. The green solid line shows the nominal mean significance and the green dashed/dotted lines show the down/up variations, respectively.
  (b) Dependence on $m_{JJ}$. The green solid line shows the line of best fit to the nominal significances, and the green dashed/dotted lines show the down/up variations on the slope term, respectively. The red points bin the individual nominal values and show the average, while the error bars indicate the same for the down/up variations of the slope term. 
}
\label{fig:CWoLa:inverted:significance_dist_corr}
\end{figure}

The correction is validated in the signal selection (no inverted rapididity cut) data in the sidebands of the fit, since after the NN selection it is expected there will not be any significant signal presence in the sidebands, and the background fit should describe the data there.
This validation is shown in Figure~\ref{fig:CWoLa:unblinded:significance_dist}.
\begin{figure}[h!]
\centering
\subfloat[]{\includegraphics[width=0.45\textwidth]{figures_CWoLa/{pulls_outSR_patience100}.pdf}}
\subfloat[]{\includegraphics[width=0.45\textwidth]{figures_CWoLa/{pulls_outSR_mjj_patience100}.pdf}}\\
\subfloat[]{\includegraphics[width=0.45\textwidth]{figures_CWoLa/{pulls_outSR_corr_patience100}.pdf}}
\subfloat[]{\includegraphics[width=0.45\textwidth]{figures_CWoLa/{pulls_outSR_mjj_corr_vars_patience100}.pdf}}\\
  \caption{Distribution of significances in signal selection (no inverted rapidity cut) data before (a,b) and after (c,d) applying the background fit correction.
  (a) Overall distribution. The green dashed line shows the mean significance and the green dotted lines show the standard error on the estimate of the mean. The $t$-stat of this estimate is shown on the plot as well.
  (b) Dependence on $m_{JJ}$. The dots show individual observations across the $6$ signal region bins at each value of $m_{JJ}$ included in the fits. The red points with error bars bin these values and show the average in order to reduce the noise. The green dashed line shows the line of best fit, and the green dotted lines show the standard error on the fit. The $t$-stat associated with the estimate of the slope of the fit line is shown on the plot as well.
  (c) Overall distribution, showing the up and down variations of the offset term. The green solid line shows the nominal mean significance and the green dashed/dotted lines show the down/up variations, respectively.
  (d) Dependence on $m_{JJ}$. The green solid line shows the line of best fit to the nominal significances, and the green dashed/dotted lines show the down/up variations on the slope term, respectively. The red points bin the individual nominal values and show the average, while the error bars indicate the same for the down/up variations of the slope term. 
}
\label{fig:CWoLa:unblinded:significance_dist}
\end{figure}
It can be seen both that before the correction, the distribution of significances and dependence on $m_{JJ}$ is consistent with that observed in the validation (inverted rapidity cut) data.
Some key statistics of the distribution are shown in Table~\ref{tab:unblinded:significance_dist}.
Both the mean significance and the slope of the significances with respect to $m_{JJ}$ are slightly higher than the values observed in the validation data.
\begin{table}[htb]
  \centering
  \caption{Key statistics of distribution of significances in signal selection data.}
  \label{tab:unblinded:significance_dist}
  \begin{tabular}{c c}
    \hline
Statistic & Value   \\ \hline
Mean & -0.10 \\
Std. Dev. &  1.06 \\
Mean Std. Err. & 0.06 \\
$m_{JJ}$ Fit Slope& -0.09~\TeV$^{-1}$  \\
$m_{JJ}$ Fit Slope Std. Err.& 0.07~\TeV$^{-1}$  \\
$m_{JJ}$ Fit Intercept& 0.19 \\
    \hline
  \end{tabular}
\end{table}

After the correction the distribution of significances is consistent with mean $0$ across the entire range to within the uncertainties, again with the nominal slightly higher since the correction is kept constant from the derivation in the validation selection data.
This indicates that the correction can also be applied to the bins in the signal regions.

\FloatBarrier
\section{Unblinded Analysis: Global Distribution of Significances}
\label{app:CWoLa:pulls}

The distribution of significances observed in the unblinded data in the given signal regions with no signal injected (Figure~\ref{fig:CWoLa:unblinded:stitched_fits} is studied under a toy Gaussian model.
In each bin, the significance $S_i$ that is being shown in the Figures is the same significance that goes into the $\chi^2$ calculation (Equation~\ref{eqn:CWoLa:signal_chi2}):
\begin{align}
S_i = \frac{O_i-E_i}{E_i}
\end{align}

Since the toy model being used is Gaussian, we only examine the significances in bins in which the background prediction $E_i>5$.
The empirical CDF $\Phi_O(x)$ of the observed significances $S_i$ is formed as:
\begin{align*}
  \Phi_O(x) = \sum_{i=1}^N\frac{\mathbbm{1}(x\le S_i)}{N}
\end{align*}
\noindent where $\mathbbm{1}$ is the indicator function, and the sum goes over all $N$ significances being considered; in this case $N=53$.

The toy model predictions are calculated by generating, in each toy, $N=53$ samples from a standard normal distribution and calculating the empirical toy CDF in the same way as for the observed.
$N_{\texttt{toys}}=20000$ empirical toy CDFs are generated in this way and quantiles across the toys are then calculated.

Figure~\ref{fig:CWoLa:cdf_pulls} shows the results of this test.
The observed empirical CDF lies well within the Gaussian expectation out to significance $x<2$.
For the most extreme excess observed in the data, this value or larger is observed in the toys at around the 1.3-$\sigma$ level, or $\sim10\%$ of the time.
\begin{figure}[h!]
\centering
\subfloat[]{\includegraphics[width=0.45\textwidth]{figures_CWoLa/{cdf_stitched_pulls_zoom_corr}.pdf}}
\caption{The CDF at each value $x$ for the observed data (orange) and for the toys (median is bold green dashed line and the green dotted lines correspond to (1,2)-$\sigma$ quantiles, respectively; the blue shadings correspond to finer quantiles at the $0.25\sigma$ level).}
\label{fig:CWoLa:cdf_pulls}
\end{figure}

\FloatBarrier
\section{Unblinded Analysis: Fits with Injected Signal}
\label{app:CWoLa:unblinded:fitsignal}
The fit results for all the signals at the injected $\mu$ value that gives rise to the limits given in Section~\ref{sec:CWoLa:unblinded:limits} can be found in Figure~\ref{fig:CWoLa:unblinded:fitsignal3000} for $m_A=3000$ GeV and in Figure~\ref{fig:CWoLa:unblinded:fitsignal5000} for $m_A$=5000 GeV.
For signals with no limit set (because the NN did not find that signal at any value of $\mu$), the fit at the maximum injected value (~\ref{tab:unblinded:injectedmu}) is shown.

\begin{figure}[h!]
\centering
\subfloat[]{\includegraphics[width=0.25\textwidth]{figures_CWoLa/{q90_sigR5_Wprime_WZqqqq_M3000_m80_m80_nS1250_rs6_patience100_1.14.20_nomask_corr}.pdf}}
\subfloat[]{\includegraphics[width=0.25\textwidth]{figures_CWoLa/{q99_sigR5_Wprime_WZqqqq_M3000_m80_m80_nS1500_rs4_patience100_1.14.20_nomask_corr}.pdf}}
\subfloat[]{\includegraphics[width=0.25\textwidth]{figures_CWoLa/{q90_sigR5_Wprime_WZqqqq_M3000_m80_m200_nS750_patience100_1.14.20_nomask_corr}.pdf}}
\subfloat[]{\includegraphics[width=0.25\textwidth]{figures_CWoLa/{q99_sigR5_Wprime_WZqqqq_M3000_m80_m200_nS1250_rs6_patience100_1.14.20_nomask_corr}.pdf}}\\
\subfloat[]{\includegraphics[width=0.25\textwidth]{figures_CWoLa/{q90_sigR5_Wprime_WZqqqq_M3000_m80_m400_nS1000_patience100_1.14.20_nomask_corr}.pdf}}
\subfloat[]{\includegraphics[width=0.25\textwidth]{figures_CWoLa/{q99_sigR5_Wprime_WZqqqq_M3000_m80_m400_nS850_rs3_patience100_1.14.20_nomask_corr}.pdf}}
\subfloat[]{\includegraphics[width=0.25\textwidth]{figures_CWoLa/{q90_sigR5_Wprime_WZqqqq_M3000_m200_m200_nS350_rs4_patience100_1.14.20_nomask_corr}.pdf}}
\subfloat[]{\includegraphics[width=0.25\textwidth]{figures_CWoLa/{q99_sigR5_Wprime_WZqqqq_M3000_m200_m200_nS225_rs5_patience100_1.14.20_nomask_corr}.pdf}}\\
\subfloat[]{\includegraphics[width=0.25\textwidth]{figures_CWoLa/{q90_sigR5_Wprime_WZqqqq_M3000_m200_m400_nS600_patience100_1.14.20_nomask_corr}.pdf}}
\subfloat[]{\includegraphics[width=0.25\textwidth]{figures_CWoLa/{q99_sigR5_Wprime_WZqqqq_M3000_m200_m400_nS600_rs6_patience100_1.14.20_nomask_corr}.pdf}}
\subfloat[]{\includegraphics[width=0.25\textwidth]{figures_CWoLa/{q90_sigR5_Wprime_WZqqqq_M3000_m400_m400_nS500_rs6_patience100_1.14.20_nomask_corr}.pdf}}
\subfloat[]{\includegraphics[width=0.25\textwidth]{figures_CWoLa/{q99_sigR5_Wprime_WZqqqq_M3000_m400_m400_nS350_rs6_patience100_1.14.20_nomask_corr}.pdf}}
\caption{The fit with an injected signal at $m_A=3000$, in signal region 5, for (a,c,e,g,i,k) $\epsilon=0.1$ and (b,d,f,h,j,l) $\epsilon=0.01$. The strength of the signal is the injected $\mu$ value that gives rise to the limits given in Section~\ref{sec:CWoLa:unblinded:limits}, or the maximum injected $\mu$ if no limits are set.
  Each signal is labeled by ($m_B,m_C$) in \GeV and $\mu$ for the two $\epsilon$ values. (a,b) (80,80), $\mu=$(1250,1500); (c,d) (80,200), $\mu=$(750,1250); (e,f) (80,400), $\mu=$(1000,850); (g,h) (200,200), $\mu=$(350,225); (i,j) (200,400), $\mu=$(600,600); (k,l) (400,400), $\mu=$(500,350). The red dashed lines indicate the fit uncertainty.}
\label{fig:CWoLa:unblinded:fitsignal3000}
\end{figure}

\begin{figure}[h!]
\centering
\subfloat[]{\includegraphics[width=0.25\textwidth]{figures_CWoLa/{q90_sigR8_Wprime_WZqqqq_M5000_m80_m80_nS1000_rs5_patience100_1.14.20_nomask_corr}.pdf}}
\subfloat[]{\includegraphics[width=0.25\textwidth]{figures_CWoLa/{q99_sigR8_Wprime_WZqqqq_M5000_m80_m80_nS1000_rs5_patience100_1.14.20_nomask_corr}.pdf}}
\subfloat[]{\includegraphics[width=0.25\textwidth]{figures_CWoLa/{q90_sigR8_Wprime_WZqqqq_M5000_m80_m200_nS750_rs5_patience100_1.14.20_nomask_corr}.pdf}}
\subfloat[]{\includegraphics[width=0.25\textwidth]{figures_CWoLa/{q99_sigR8_Wprime_WZqqqq_M5000_m80_m200_nS1000_patience100_1.14.20_nomask_corr}.pdf}}\\
\subfloat[]{\includegraphics[width=0.25\textwidth]{figures_CWoLa/{q90_sigR8_Wprime_WZqqqq_M5000_m80_m400_nS1000_rs3_patience100_1.14.20_nomask_corr}.pdf}}
\subfloat[]{\includegraphics[width=0.25\textwidth]{figures_CWoLa/{q99_sigR8_Wprime_WZqqqq_M5000_m80_m400_nS1000_rs3_patience100_1.14.20_nomask_corr}.pdf}}
\subfloat[]{\includegraphics[width=0.25\textwidth]{figures_CWoLa/{q90_sigR8_Wprime_WZqqqq_M5000_m200_m200_nS75_patience100_1.14.20_nomask_corr}.pdf}}
\subfloat[]{\includegraphics[width=0.25\textwidth]{figures_CWoLa/{q99_sigR8_Wprime_WZqqqq_M5000_m200_m200_nS150_patience100_1.14.20_nomask_corr}.pdf}}\\
\subfloat[]{\includegraphics[width=0.25\textwidth]{figures_CWoLa/{q90_sigR8_Wprime_WZqqqq_M5000_m200_m400_nS280_rs4_patience100_1.14.20_nomask_corr}.pdf}}
\subfloat[]{\includegraphics[width=0.25\textwidth]{figures_CWoLa/{q99_sigR8_Wprime_WZqqqq_M5000_m200_m400_nS750_rs6_patience100_1.14.20_nomask_corr}.pdf}}
\subfloat[]{\includegraphics[width=0.25\textwidth]{figures_CWoLa/{q90_sigR8_Wprime_WZqqqq_M5000_m400_m400_nS50_rs4_patience100_1.14.20_nomask_corr}.pdf}}
\subfloat[]{\includegraphics[width=0.25\textwidth]{figures_CWoLa/{q99_sigR8_Wprime_WZqqqq_M5000_m400_m400_nS50_rs4_patience100_1.14.20_nomask_corr}.pdf}}
\caption{The fit with an injected signal at $m_A=5000$, in signal region 8, for (a,c,e,g,i,k) $\epsilon=0.1$ and (b,d,f,h,j,l) $\epsilon=0.01$. The strength of the signal is the injected $\mu$ value that gives rise to the limits given in Section~\ref{sec:CWoLa:unblinded:limits}, or the maximum injected $\mu$ if no limits are set.
  Each signal is labeled by ($m_B,m_C$) in \GeV and $\mu$ for the two $\epsilon$ values. (a,b) (80,80), $\mu=$(750,280); (c,d) (80,200), $\mu=$(750,750); (e,f) (80,400), $\mu=$(1000,350); (g,h) (200,200), $\mu=$(75,75); (i,j) (200,400), $\mu=$(280,500); (k,l) (400,400), $\mu=$(50,50).
The red dashed lines indicate the fit uncertainty.}
\label{fig:CWoLa:unblinded:fitsignal5000}
\end{figure}

\FloatBarrier
\section{Unblinded Analysis: Dependence of Limits on $\mu$}
\label{app:CWoLa:unblinded:limits_mu}
The 95\% CL exlusion limits on the given signals as a function of $\mu$ are given in Figure~\ref{fig:CWoLa:unblinded:limits_mu_3000} for signals with $m_A=3000$ GeV and in Figure~\ref{fig:CWoLa:unblinded:limits_mu_5000} for signals with $m_A=5000$ GeV.
The limits for each of the $5$ different random samplings of the signal is included.
The network that gives rise to the median limit on the signal is also indicated, and the $\pm1\sigma$ and $\pm2\sigma$ bands and observed limit are indicated for this network; this is the network that is used to derive the final limits.
The envelope of the outputs across the different random samplings tends to be small when the NN efficiency is very high (when it is very low the limits are large and worse than existing limits), while the envelope widens at the $\mu$ values where the efficiency is middling; these are exactly the transition regions where the NN can find the signal but does not always.
The median limit tends to be smoothly falling with $\mu$ (before taking the $\max$ with the dotted line $\mu$), while single samplings from the envelope may not be; thus, the choice to run the analysis with different random samplings serves as a smoothing procedure.
For $m_A=5000$ GeV, for the best-performing signals at high $m_B,m_C$, the limits actually get worse with increasing $\mu$; this is related to the fact that the NN efficiency gets worse with increasing $\mu$ for these signals (Appendix~\ref{app:CWoLa:unblinded:NNeff_mu}).

\begin{figure}[h!]
\centering
\subfloat[]{\includegraphics[width=0.25\textwidth]{figures_CWoLa/{limits95_mu_q90_M3000_m80_m80_corr}.pdf}}
\subfloat[]{\includegraphics[width=0.25\textwidth]{figures_CWoLa/{limits95_mu_q99_M3000_m80_m80_corr}.pdf}}
\subfloat[]{\includegraphics[width=0.25\textwidth]{figures_CWoLa/{limits95_mu_q90_M3000_m80_m200_corr}.pdf}}
\subfloat[]{\includegraphics[width=0.25\textwidth]{figures_CWoLa/{limits95_mu_q99_M3000_m80_m200_corr}.pdf}}\\
\subfloat[]{\includegraphics[width=0.25\textwidth]{figures_CWoLa/{limits95_mu_q90_M3000_m80_m400_corr}.pdf}}
\subfloat[]{\includegraphics[width=0.25\textwidth]{figures_CWoLa/{limits95_mu_q99_M3000_m80_m400_corr}.pdf}}
\subfloat[]{\includegraphics[width=0.25\textwidth]{figures_CWoLa/{limits95_mu_q90_M3000_m200_m200_corr}.pdf}}
\subfloat[]{\includegraphics[width=0.25\textwidth]{figures_CWoLa/{limits95_mu_q99_M3000_m200_m200_corr}.pdf}}\\
\subfloat[]{\includegraphics[width=0.25\textwidth]{figures_CWoLa/{limits95_mu_q90_M3000_m200_m400_corr}.pdf}}
\subfloat[]{\includegraphics[width=0.25\textwidth]{figures_CWoLa/{limits95_mu_q99_M3000_m200_m400_corr}.pdf}}
\subfloat[]{\includegraphics[width=0.25\textwidth]{figures_CWoLa/{limits95_mu_q90_M3000_m400_m400_corr}.pdf}}
\subfloat[]{\includegraphics[width=0.25\textwidth]{figures_CWoLa/{limits95_mu_q99_M3000_m400_m400_corr}.pdf}}\\
\caption{The limits $\mu_{95}(\mu)$ as a function of $\mu$ on the injected signal at $m_A=3000$, in signal region 5, for (a,c,e,g,i,k) $\epsilon=0.1$ and (b,d,f,h,j,l) $\epsilon=0.01$. 
  There are 5 lines corresponding to the expected limit for the $5$ different random samplings of the signal in the training of the NN; the network with the median expected limit is also marked.
  The $\pm1\sigma$ and $\pm2\sigma$ bands and the observed limit are given for the network that gives rise to the median expected limit.
  The red stars indicate the expected, observed, and bands of the limit after taking the $\max$ of the limit and $\mu$.
  Each signal is labeled by ($m_B,m_C$) in \GeV. (a,b) (80,80); (c,d) (80,200); (e,f) (80,400); (g,h) (200,200); (i,j) (200,400); (k,l) (400,400).
}
\label{fig:CWoLa:unblinded:limits_mu_3000}
\end{figure}

\begin{figure}[h!]
\centering
\subfloat[]{\includegraphics[width=0.25\textwidth]{figures_CWoLa/{limits95_mu_q90_M5000_m80_m80_corr}.pdf}}
\subfloat[]{\includegraphics[width=0.25\textwidth]{figures_CWoLa/{limits95_mu_q99_M5000_m80_m80_corr}.pdf}}
\subfloat[]{\includegraphics[width=0.25\textwidth]{figures_CWoLa/{limits95_mu_q90_M5000_m80_m200_corr}.pdf}}
\subfloat[]{\includegraphics[width=0.25\textwidth]{figures_CWoLa/{limits95_mu_q99_M5000_m80_m200_corr}.pdf}}\\
\subfloat[]{\includegraphics[width=0.25\textwidth]{figures_CWoLa/{limits95_mu_q90_M5000_m80_m400_corr}.pdf}}
\subfloat[]{\includegraphics[width=0.25\textwidth]{figures_CWoLa/{limits95_mu_q99_M5000_m80_m400_corr}.pdf}}
\subfloat[]{\includegraphics[width=0.25\textwidth]{figures_CWoLa/{limits95_mu_q90_M5000_m200_m200_corr}.pdf}}
\subfloat[]{\includegraphics[width=0.25\textwidth]{figures_CWoLa/{limits95_mu_q99_M5000_m200_m200_corr}.pdf}}\\
\subfloat[]{\includegraphics[width=0.25\textwidth]{figures_CWoLa/{limits95_mu_q90_M5000_m200_m400_corr}.pdf}}
\subfloat[]{\includegraphics[width=0.25\textwidth]{figures_CWoLa/{limits95_mu_q99_M5000_m200_m400_corr}.pdf}}
\subfloat[]{\includegraphics[width=0.25\textwidth]{figures_CWoLa/{limits95_mu_q90_M5000_m400_m400_corr}.pdf}}
\subfloat[]{\includegraphics[width=0.25\textwidth]{figures_CWoLa/{limits95_mu_q99_M5000_m400_m400_corr}.pdf}}\\
\caption{The limits $\mu_{95}(\mu)$ as a function of $\mu$ on the injected signal at $m_A=5000$, in signal region 8, for (a,c,e,g,i,k) $\epsilon=0.1$ and (b,d,f,h,j,l) $\epsilon=0.01$. 
  There are 5 lines corresponding to the expected limit for the $5$ different random samplings of the signal in the training of the NN; the network with the median expected limit is also marked.
  The $\pm1\sigma$ and $\pm2\sigma$ bands and the observed limit are given for the network that gives rise to the median expected limit.
  The red stars indicate the expected, observed, and bands of the limit after taking the $\max$ of the limit and $\mu$.
  Each signal is labeled by ($m_B,m_C$) in \GeV. (a,b) (80,80); (c,d) (80,200); (e,f) (80,400); (g,h) (200,200); (i,j) (200,400); (k,l) (400,400).
}
\label{fig:CWoLa:unblinded:limits_mu_5000}
\end{figure}

\FloatBarrier
\section{Computing Resources}
\label{app:CWoLa:computing}

The time for training depends on the signal region.
The initial factor of 3 networks to find the one with the lowest validation loss is done sequentially in a single job, but everything else is parallelized.
For signal region 4 (the largest), a single training takes $\mathcal{O}$(hours), and decreases proportionally according to the number of events in the signal region + sidebands.
For a single mass point, $\mu$ value, and signal region, we have $4\times 5 = 20$ such jobs.
For the no-signal networks, there are therefore $20\times 5$ jobs, some of which run very quickly.

There are far more jobs with injected signal.
We look at 12 signal mass points, and $\mathcal{O}(10)$ $\mu$ values for each, and for a given signal hypothesis only in a single signal region.
For the full unblinded analysis each training is repeated $5$ times with random samplings of the signal.
Therefore, for the full unblinded analysis, there are $4\times 5\times 12\times 10\times 5 = 12000$ jobs.
The Author is especially grateful for the \href{https://atlas.slac.stanford.edu/using-the-slac-computing-resourcesi}{computing resources at SLAC}, which provide a batch CPU system on which a single user can reliably run about 400 jobs simultaneously.
Altogether it takes $\mathcal{O}$(days-weeks) in compute time to reproduce all the results in this analysis. 

Each job stores $\mathcal{O}(100)$ MB of data in output, since there are tens of millions of events for which a few key features have to be stored, e.g. the NN output and the values of the features and $m_{JJ}$.
Probably wastefully, each step of the validation combination process is stored as a new file, in order to reduce computation time, increasing the amount of storage by a factor of $\sim 2$.
Therefore the whole analysis uses a few TB in storage space, which again we are grateful to the SLAC computing facilities for providing and maintaining.

\section{Alternatives to CWoLa Hunting}
\label{app:CWoLa:alternatives}

A variety of searches have been proposed (with and without machine learning) which basically test the compatibility of the observed data with the background-only hypothesis in a portmanteau test by comparing the observed data directly to the simulation of the background~\cite{DAgnolo:2018cun,DeSimone:2018efk,CMS:2017yoc,Aaboud:2018ufy}.
These searches obviously rely heavily on accurate simulations of the background processes, while CWoLa hunting does not use any background simulations in the final analysis pipeline.

As more direct competitors to CWoLa hunting, many searches have been proposed based on autoencoders~\cite{Farina:2018fyg,Heimel:2018mkt,Roy:2019jae,Cerri:2018anq,Blance:2019ibf,Hajer:2018kqm}, as well as other unsupervised techniques that do not use autoencoders~\cite{1809.02977,Dillon:2019cqt}.
These techniques must also be combined with a background estimation strategy, either in the form of a bump hunt, or using simulation, similarly to CWoLa hunting.
The main difference between these techniques and CWoLa hunting is that they are \textit{un}supervised, while CWoLa hunting is \textit{weakly} supervised.
I.e., the unsupervised methods simply find natural groupings or patterns in the data, and it may be the case that a new signal does not fit into those groupings or follow those patterns so that the unsupervised network can tag these as anomalies (however such an outcome is not guaranteed).
The weakly supervised method, on the other hand, does see the signal during its training, if it exists, and so therefore can be biased towards better tagging the signal.
Because of this difference, when signal rates are large enough such that the weakly supervised network can learn some information to tag the signal itself, the weak supervision method is superior.
On the other hand, the unsupervised approaches can do better when there is very little signal.

