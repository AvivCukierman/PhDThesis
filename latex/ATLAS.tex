\newcommand{\AtlasCoordFootnote}{
ATLAS uses a right-handed coordinate system with its origin at the nominal interaction point (IP)
in the center of the detector and the $z$-axis along the beam pipe.
The $x$-axis points from the IP to the center of the LHC ring,
and the $y$-axis points upwards.
Cylindrical coordinates $(r,\phi)$ are used in the transverse plane, 
$\phi$ being the azimuthal angle around the $z$-axis.
The pseudorapidity is defined in terms of the polar angle $\theta$ as $\eta = -\ln \tan(\theta/2)$.
Angular distance is measured in units of $\Delta R \equiv \sqrt{(\Delta\eta)^{2} + (\Delta\phi)^{2}}$.}

\section{Introduction}
The ATLAS detector~\cite{PERF-2007-01} is a general-purpose particle physics detector 
with nearly $4\pi$ coverage in solid angle around the collision point.\footnote{\AtlasCoordFootnote}
The physics results that ATLAS produce are enabled not only by the hardware that measures the properties of outgoing particles, but also by software which simulates, stores, and processes this enormous amount of data.

The detector itself is designed to have many concentric layers serving different purposes, in particular to detect and identify all kinds of particles that may be encountered from the collisions at the LHC (Section~\ref{sec:ATLAS:ATLAS}).

The physics phenomena that occur in the $pp$ collisions provided by the LHC and their subsequent interactions with the ATLAS detector are simulated using a variety of generators and a detailed detector simulation (Section~\ref{sec:ATLAS:simulation}).

Because of the extremely high rate of events and large amount of data read out per event, there is a trigger system which lowers the rate that is written to disk (Section~\ref{sec:ATLAS:trigger}).

Finally, the readouts of all the various detector subsystems are combined to construct objects intended to match individual Standard Model particles (Section~\ref{sec:ATLAS:objects}).
Tracks and calorimeter clusters are combined to form detector-level photons, electrons, taus, jets (Chapter~\ref{ch:Jets}), and muons.
All of these objects are taken together to calculate the missing energy in the event which could be due to neutrinos or beyond-the-Standard-Model physics.

\section{Hardware}
\label{sec:ATLAS:ATLAS}
As mentioned above, the ATLAS detector (A Toroidal LHC ApparatuS) is a general purpose particle physics detector built around the nominal interaction point for $pp$ collisions provided by the LHC\footnote{This Section is sourced mainly from the description of ATLAS in~\cite{PERF-2007-01}; however, the Author is also grateful for the additional explanations that can be found in previous SLAC ATLAS students' PHD theses, in particular~\cite{Swiatlowski:2040684} and~\cite{Nachman:2016qyc}. The later Sections of this Chapter also benefit from these sources.}.
It is an enormous instrument, roughly cylindrical with a diameter of about 25 m and a length of about 44 m.
A cutout of the ATLAS detector with some parts labeled can be seen in Figure~\ref{fig:ATLAS:ATLAS}.

\begin{figure}[htbp]
  \centering 
  \subfloat[]{\includegraphics[width=0.8\textwidth]{figures/{figures_AtlasDetectorLabelled.png}}}
  \caption{A cutout view of the ATLAS detector with major subsystems labeled. People included for scale. Figure sourced from~\cite{PERF-2007-01}.}
  \label{fig:ATLAS:ATLAS}
\end{figure}

ATLAS consists of an inner tracking detector surrounded by a superconducting solenoid providing a \SI{2}{\tesla} axial magnetic field (Section~\ref{sec:ATLAS:tracker}), a system of calorimeters (Section~\ref{sec:ATLAS:calorimeter}), and a muon spectrometer incorporating three large superconducting toroid magnets (Section~\ref{sec:ATLAS:MS}).
The various layers target different kinds of particles based on their interactions with matter, as can be seen in Figure~\ref{fig:ATLAS:schematic}.

\begin{figure}[htbp]
  \centering 
  \subfloat[]{\includegraphics[width=0.5\textwidth]{figures/{ATLAS_schematic.jpg}}}
  \caption{A schematic of various particles passing through the ATLAS detector. Figure sourced from ~\cite{Pequenao:1096081}.}
  \label{fig:ATLAS:schematic}
\end{figure}

This schematic only shows the ideal or targeted case; in practice the object identification is a non-trivial problem (Section~\ref{sec:ATLAS:objects}).
Charged particles leave tracks in the tracker, which is surrounded by a solenoid magnet to bend their tracks and measure charge and momentum.
Photons and electrons are stopped and their energies measured in the electromagnetic calorimeter, while hadrons interact to a lesser extent and are ultimately stopped and measured in the hadronic calorimeter.
Muons pass through the entire calorimeter system and are measured in the muon system, which is surrounded by superconducting toroids.
Finally, neutrinos interact only very weakly with matter and pass right through the detector; these can only be reconstructed as missing energy and momentum in the event.

\subsection{Tracker}
\label{sec:ATLAS:tracker}
The tracker, or inner detector (as it is the closest part of ATLAS to the beamline), consists of 3 layers with different technologies: the silicon pixel detectors, the semiconductor strip tracker (SCT), and the transition radiation tracker (TRT).
The entire tracking system is immersed in a 2 T magnetic field provided by a surrounding solenoid.
These components, when taken together, provide charged-particle tracking in the range $|\eta| < 2.5$.
A cutout view of the tracking system can be seen in Figure~\ref{fig:ATLAS:tracker}.
\begin{figure}[htbp]
  \centering 
  \subfloat[]{\includegraphics[width=0.5\textwidth]{figures/{ATLAS_tracker}.png}}
  \caption{A cutout view of the tracking system showing the various layers. Figure sourced from~\cite{ATL-PHYS-PUB-2015-018}.}
  \label{fig:ATLAS:tracker}
\end{figure}

The pixel detectors are the innermost part of the ATLAS detector to the beamline.
The original design included 3 layers, although a 4th layer, the insertable $B$-layer (IBL), was installed between Run 1 and Run $2$ in 2014.
The pixel detectors are composed of silicon and operate as ionizing radiation detectors.
As charged particles pass through the material, electrons are knocked loose and these are measured in each individual pixel, without substantially affecting the momentum of the charged particle.
The pixel system has very good spatial resolution, with each pixel having a size of $50\times 400$ $\mu\text{m}^2$ in the outer 3 layers and $50\times 250$ $\mu\text{m}^2$ in the IBL.
There is both a cylindrical set of pixel detectors in the barrel and an endcap set on the ends.
The accuracies of the pixels are $10\times 115$ $\mu\text{m}^2$ in $R-\phi \times z$ in the barrel and also $10\times 115$ $\mu\text{m}^2$ in $R-\phi \times R$ in the endcaps.
There are roughly 80.4 million independent pixel channels.

The next outermost layer is the SCT, which operates under very similar principles to the pixel detectors.
However, insted of small pixels long and thin strips are used, which provide spatial information in only one direction.
Because of this, each of the 4 layers of the SCT are actually composed of 2 layered and slightly offset strips at an angle of 40 mrad to each other, in order to get a (rough) measurement in the second direction as well.
In the barrel region these strips are parallel to the beam direction; in the endcaps they are radial.
The strips have an accuracy of $17\times 580$ $\mu\text{m}$ in $R-\phi \times z$ in the barrel and also $17\times 580$ $\mu\text{m}$ in $R-\phi \times R$ in the endcaps.
There are approximately 6.3 million readout channels in the SCT.

The final layer consists of the TRT, which is composed of $4$ mm (in diameter) drift tubes.
These drift tubes are not made out of silicon, but rather are filled with gas which, as charged particles pass through, gets ionized; this signal is amplified by a large voltage difference (1530 V) between the center and exterior of the tube.
The tubes do not provide any $z$ resolution, but only information in $R-\phi$ with an accuracy of 130 $\mu\text{m}$, both in the barrel and endcap regions.
However, this is mitigated somewhat by every particle passing through about 30 tubes before exiting the tracker.
There are approximately 351000 readout channels in the TRT.

The entire tracking system is surrounded by a superconducting solenoid which generates an axial field of 2 T.
As charged particles pass through this magnetic field, their total momentum is not changed as magnetic fields do no work, but the direction of the momentum curves in the $\phi$ direction with the radius of curvature determined by the charge-to-(transverse) momentum ratio.

The individual hits in the various layers are combined together in software to identify paths of charged particles through the tracker and magnetic field, measuring both the charge and momentum of the charged particle (Section~\ref{sec:ATLAS:tracks}).

\subsection{Calorimeters}
\label{sec:ATLAS:calorimeter}
The ATLAS calorimeter system is designed to stop and measure the energy of all charged and neutral particles that exit the tracker other than muons and neutrinos.
These calorimeters cover the region $|\eta| < 4.9$, in comparison to the tracker which only covers $|\eta|<2.5$. 
The calorimeter system consists of two main subsystems: the inner electromagnetic calorimeter, which is intended to interact electromagnetically and measure particles like photons and electrons, and the outer hadronic calorimeter, which is intended to interact both electromagnetically and via nuclear interactions in order to measure hadronic particles.
A cutout view of the calorimeter system can be seen in Figure~\ref{fig:ATLAS:calorimeters}.
\begin{figure}[htbp]
  \centering 
  \subfloat[]{\includegraphics[width=0.8\textwidth]{figures/{ATLAS_calorimeters}.png}}
  \caption{A cutout view of the calorimeter system showing the various subsystems. Figure sourced from~\cite{PERF-2007-01}.}
  \label{fig:ATLAS:calorimeters}
\end{figure}

Both subsystems are sampling calorimeters which operate under the principle of alternating passive and active layers.
The passive layers are made of some dense material (lead, steel, copper, or tungsten) that have high probability of interacting with the energetic particles passing through them, causing a cascade of lower energy radiation that is easier to measure (\textit{sample}) in the active materials.
The active materials use ionization or scintillation to measure the energies of the particles passing through them.
In ioniziation, the material is ionized by electrons being knocked free; the free electrons are then drifted to the side of the cell and measured.
In scintillation, excited molecules emit photon radiation which can then be read out by photomultiplier tubes.
All systems are non-compensating, meaning they do not account for energy loss in the passive layers; this is one cause for the need to calibrate the energy of physics objects formed in the calorimeter, in particular jets (Section~\ref{sec:ATLAS:jet_calibration}).
However, the innermost layer of electromagnetic calorimeter is a presampler which does compensate for the energy loss in the tracker.

High energy charged electrons and positrons interacting with nuclei in the materials are dominated by bremsstrahlung, which is photon radiation due to deceleration in the material~\cite{Lechner:2674116}.
High energy photons, in turn, primarily convert to electron-positron pairs in the field of nuclei, which further lose energy to bremsstrahlung; this back-and-forth is referred to as an \textit{electromagnetic shower}.
Below a certain energy (depending on the material, but usually some MeV), other processes take over.
Muons can be considered to be heavy electrons; however, because of their higher mass, bremmstrahlung does not dominate until the muon energy is above $\sim 1000$ GeV~\cite{TASI_day3_school}; thus muons tend to pass through the entire calorimeter without losing much energy and can only be measured in the muon spectrometer (Section~\ref{sec:ATLAS:MS}).

The loss of energy in an electromagnetic shower at high energies can be characterized as
\begin{align}
\frac{dE}{dx} = -\frac{E}{X_0},
\label{eqn:ATLAS:radiation}
\end{align}
where $X_0$ is called the \textit{radiation length}, and is characteristic of the interacting material. 
The solution to~\ref{eqn:ATLAS:radiation} implies an exponential loss of energy as a function of distance in the material, meaning the shower length is logarithmic in initial energy and also that a fixed size detector can cover many orders of magnitude of energy.

For nuclear interactions the underlying processes are more complicated, but the \textit{hadronic interaction length} $\lambda$ gives a similar length scale for hadrons passing through a material and forming \textit{hadronic showers}~\cite{TASI_day3_school} of pions, photons, and positrons/electrons.
For dense materials $\lambda > X_0$ by a factor of 5-10~\cite{Lechner:2674116}, implying that hadronic showers are much longer and occur later than electromagnetic showers; this is why the hadronic calorimeter is outside the electromagnetic calorimeter.

The electromagnetic calorimeter is broken down into the barrel, which covers $|\eta|<1.475$, and two end-caps which cover $1.375<|\eta|<3.2$.
Each of these have three layers in addition to the innermost presampler layer.
Both of these use lead as the passive material and liquid argon (LAr) as the active material, which measures the energy of particles via ionization.
The total thickness of the electromagnetic calorimeter is $>22 X_0$ in the barrel and $>24 X_0$ in the endcaps.
The size of the calorimeter cells vary with $\eta$ and depth, but the smallest cells, which occur in the second layer, are $0.025 \times 0.025$ in $\Delta\eta \times \Delta\phi$.

The hadronic calorimeter consists of the barrel, which covers $|\eta|<1.7$, two end-caps which cover $1.5<|\eta|<3.2$, and two forward calorimeters which cover $3.1<|\eta|<4.9$.
These three components consist of 3, 4, and 3 independent layers respectively.
The barrel uses steel as the passive material and scintillating tiles as the active material; however, the end-caps and forward calorimeters use ionizing LAr as the active material, with copper (in the end-caps and the first layer of the forward calorimeter) and tungsten (in the second and third layers of the forward calorimeter) as the passive materials.
The total thickness of the hadronic calorimeter is $\gtrsim 10\lambda$ over the entire detector.
The smallest calorimeter cells in the barrel and end-caps are $0.1 \times 0.1$ in $\Delta\eta \times \Delta\phi$.
In the forward calorimeters, $\eta$ increases rapidly with $\theta$, so the sizes are simply measured on an absolute scale, with the smallest cells $3.0 \times 2.6$ $\text{cm}^2$ in $\Delta x \times \Delta y$.

\subsection{Muon System}
\label{sec:ATLAS:MS}
The outermost radial component of the detector is the muon system, or muon spectrometer (MS).
In principle due to the interactions with the calorimeters the only particles that can make it out so far are muons; the MS provides measurements of muon tracks out to $|\eta|<2.7$, with an additional triggering system that goes out to $|\eta|<2.4$.
However, very energetic hadrons can ``punch through'' to the MS; the energy of jets therefore not measured in the calorimeter can be corrected (Section~\ref{sec:ATLAS:jet_calibration}).
A cutout view of the MS can be seen in Figure~\ref{fig:ATLAS:MS}.
\begin{figure}[htbp]
  \centering 
  \subfloat[]{\includegraphics[width=0.8\textwidth]{figures/{ATLAS_MS}.png}}
  \caption{A cutout view of the muon system showing the various subsystems. Figure sourced from~\cite{PERF-2007-01}.}
  \label{fig:ATLAS:MS}
\end{figure}

The MS is surrounded by a toroid magnet system which bends muons in the $\pm z/\eta$ direction in the barrel.
In the barrel, there are eight toroids arranged symmetrically about the beam axis; there are in addition two end-cap toroids.

The main component of the MS are the monitored drift tubes (MDT), which operate similarly to the TRTs in Section~\ref{sec:ATLAS:tracker}.
These cover the region $|\eta|<2.7$, with three layers out to $|\eta|<2.0$ and two beyond that.
As drift tubes, they provide a resolution of $35$ $\mu\text{m}$ in the $z$ direction and no measurement in the $\phi$ direction; this choice of orientation is intended to measure the trajectory of the muons in the magnetic field and therefore their momentum.
In addition, the drift time in the MDTs is large (approximately $700$ ns) relative to the frequency of bunch crossings ($25$ ns), so that other systems must be used to trigger (Section~\ref{sec:ATLAS:trigger}) on muons.

Cathode-strip chambers (CSC) provide tracking measurements in the end-cap region $2.0<|\eta|<2.7$ with alternating layers of perpendicular strips.
The CSCs are multi-wire proportional chambers which drift electrons from the inside to the outside of the chamber.
Because of the perpendicular strips, the CSCs provide measurements in both directions, with a resolution of $40$ $\mu\text{m}$ $\times$ $5$ $\text{mm}$ in $R \times \phi$.

The muon triggering system is provided by the resistive plate chambers (RPC) in the barrel region $|\eta|<1.05$, and by thin-gap chambers (TGC) in the end-cap region $1.05<|\eta|<2.4$.
The RPCs are parallel plate capacitors filled with gas which are segmented in order to provide measurements in both directions, $10\times 10$ $\text{mm}^2$ in $z \times \phi$.
The drift time in the parallel plates is significantly less than in the MDTs, allowing for use in triggering.
The TGCs are multi-wire proportional chambers similar to the CSCs, and provide resolution of about $5\times 5$ $\text{mm}^2$ in $R \times \phi$.

\section{Simulation}
\label{sec:ATLAS:simulation}
Every analysis in ATLAS relies on simulated events in some way.
Both of the analyses presented in this Thesis (Chapter~\ref{ch:HBSM} and Chapter~\ref{ch:CWoLa}) are searches for new BSM physics; since BSM particles have never been observed, simulations are required to understand the sensitivity of the analysis to these new signals.
Many analyses in ATLAS use simulations to model their background - both of these searches avoid this by estimating the background in a data-driven way, but still require simulations of the background in order to set up and validate the analysis chain.
Furthermore, a major step of object calibrations is understanding the effect of the detector in simulated events, which is the subject of Chapters~\ref{ch:NI} and~\ref{ch:GenNI}.
These are just some of the ways that simulations are used in ATLAS.

Simulations of physics events are \textit{factorized}, often using different software programs entirely for matrix element calculations and parton showering, fragmentation and hadronization, and detector simulation~\cite{powhegintro}.
Fundamentally each step of this process is random due to quantum effects, so events are simulated via Monte Carlo, or \textit{MC}, methods to fully populate the relevant probability distributions.
Since even the most common ``interesting'' physics processes have cross sections on the order of $10^{-5}$ of the total $pp$ cross section, and many other important processes are much rarer still, events are typically simulated not inclusively but rather by first specifying the underlying \textit{hard-scatter} (i.e., the tree-level $pp$ interaction) process and proceeding from there.

The matrix element calculations cover the initial $2\rightarrow N$ interactions of the constituent quarks in the colliding protons at the very high energies of the beams.
The parton showering further simulates the produced partons as they radiate down to the hadronization scale around $\mathcal{O}($GeV$)$.
Because the energies in these steps are above the hadronization scale, they can be calculated perturbatively at fixed order in $\alpha_s$, and the generators are specified as to what order they go to (leading order ``LO'', next-to-leading order ``NLO'', etc.).
The three most common generators in use are \PYTHIA~\cite{Sjostrand:2007gs,Sjostrand:2014zea}, \SHERPA~\cite{Gleisberg:2008ta}, and \HERWIG~\cite{Bahr:2008pv,Bellm:2015jjp}.
Each of these can use \POWHEGBOX~\cite{Frixione:2007vw,Alioli:2010xd} to interface between the matrix element and parton showering.
Often a single generator will be used primarily for the simulated events in an analysis, and one or multiple other generators will be used to estimate the uncertainties related to the theoretical calculations.

The fragmentation and hadronization covers the conversion of partons to hadrons.
This process is not described well by any fundamental theory, and so the generators use phenomenological models that are tuned to empirical data (e.g.,~\cite{ATL-PHYS-PUB-2014-021}); similarly, generators are specified by this hadronization tune.
The underlying event that comes from the soft interactions of the proton constituents is also simulated at this stage, with the parton distribution functions again coming from phenomenological models~\cite{Lai:2010vv}.
These are also typically covered by the above-mentioned generators.
The decays of heavy flavor hadrons (those containing bottom and charm quarks) are also simulated at this stage using dedicated programs like EvtGen~\cite{Lange:2001uf}.

The other simultaneous $pp$ collisions in the event (pile-up) are not simulated but rather overlay minimum bias (i.e., minimal triggering requirements) events on top of the simulated ones, according to the expected number of interactions in the event.

The above-mentioned steps constitute what is known as the ``truth'' event.
The observables related to the particles at this stage (in particular, the four-momentum) are not accessible in real life, because they have to be observed in the detector (Section~\ref{sec:ATLAS:ATLAS}).
The simulated events are passed through a full simulation of the ATLAS detector modeled in \GEANT\cite{Agostinelli:2002hh}.
This simulates both the particle interactions with the material and the resulting digitization of the signals.
This is considered to be the ``reconstructed'' event, which is in the exact same format that real data would be observed.
The reconstructed event is passed through various post-processing stages (Section~\ref{sec:ATLAS:objects}), the overall goal of which is to attempt to construct the ``truth'' event that would have given rise to the ``reconstructed'' (nonsimulated) event as well as possible.

The majority of ATLAS computing resources are dedicated to running simulations.
Figure~\ref{fig:ATLAS:simulation} shows the fraction of disk space and CPU time projected to be needed in 2028 for the various ATLAS computing activities.
For the disk space, about 75\% of the roughly 1500 petabytes needed by ATLAS by 2028~\cite{computingandsoftware} will be dedicated to simulations (``MC'' in the Figure).
Similarly, for the CPU time, about 75\% of the roughly 20 MHS06\footnote{A HS06 is a CPU benchmark tailored for high energy physics typical use cases~\cite{hepix}. Typical high-performance CPUs are equivalent to 500-1000 HS06. A MHS06 is a mega-HS06, or 1 million HS06.} needed by ATLAS by 2028~\cite{computingandsoftware} will be dedicated to simulations (``MC'' and ``EvGen'' in the Figure).

\begin{figure}[htbp]
  \centering 
  \subfloat[]{\includegraphics[width=0.5\textwidth]{figures/{disk2028_baseline}.pdf}}
  \subfloat[]{\includegraphics[width=0.5\textwidth]{figures/{cpu2028}.pdf}}
  \caption{Projected computing resources needed by ATLAS in 2028. (a) Disk space. (b) CPU resources.Figures sourced from~\cite{computingandsoftware}.}
  \label{fig:ATLAS:simulation}
\end{figure}


\section{Trigger}
\label{sec:ATLAS:trigger}
The trigger system lies somewhere between the hardware and software systems\footnote{This Section is sourced mainly from~\cite{TRIG-2016-01}, with additional most recent information from~\cite{Martinez:2016udm} and~\cite{ATLAS-TRIG-2019-04-001} (which is not yet public at the time of writing).}.
Because of the enormous rate of collisions provided by the LHC ($40$ MHz), it is infeasible to store every event.
Every event takes up $\mathcal{O}($MB$)$~\cite{Buckley:2014150} on disk, so storing every event would be equivalent to $\mathcal{O}(100$ TB$)$ per second rate of writing, or about $10^6$ PB for a full year's worth of data-taking\footnote{As a piece of trivia, this amount of data is called a \textit{zetta}byte, or ZB\cite{si-brochure}.}.
Moreover, it is not desirable to store every event, because even the most common ``interesting'' interactions have a cross section $10^{-5}$ times the overall $pp$ cross section, and many others are far rarer.
This can be seen, for example, in Figure~\ref{fig:ATLAS:xs} - $\sigma_W$ ($W$+jets) has a cross section about $10^{-5}$ of the total cross section.
\begin{figure}[htbp]
  \centering 
  \subfloat[]{\includegraphics[width=0.5\textwidth]{figures/{crosssections2012_v5}.pdf}}
  \caption{Cross sections for $pp$ interactions as a function of $\sqrt{s}$ center-of-mass energy. Figure sourced from~\cite{StirlingXS}.}
  \label{fig:ATLAS:xs}
\end{figure}
This paucity of ``interesting'' physics motivates the choice to set up multiple (in 2018, about $60$~\cite{luminositypublic}) proton-proton interactions per bunch crossing, or \textit{pile-up} - in order to increase the probability of a such an interaction to occur in any given bunch crossing.

Because of the reasons outlined above, ATLAS institutes a \textit{trigger} system~\cite{TRIG-2016-01} to decide whether or not to store each event, based on whether the reconstructed objects and topology in the event are indicative of some particular physics process.
The reconstruction algorithms in use in ATLAS are distinguished by whether they are \textit{online}, meaning they are in use in the trigger and are subject to the relevant time and space constraints, or if they are \textit{offline}, meaning they are used on events passing the trigger and can be optimized for performance using the full detector information and (basically) no time constraints\footnote{Subject to the CPU resources available to the offline analyzer.}.

The trigger consists of two major subsystems.
First, the hardware-based \textit{Level 1} trigger, or \textit{L1}, reduces the rate of events from $40$ MHz to about $100$ kHz based on fast but approximate algorithms.
Then, the software-based \textit{high-level trigger}, or \textit{HLT}, uses offline-like algorithms (Section~\ref{sec:ATLAS:objects}) to further reduce the rate to about $1$ kHz.
The rates of each of these two trigger levels, along with some of the main individual triggers, can be seen in Figure~\ref{fig:ATLAS:trigger}.

\begin{figure}[htbp]
  \centering 
  \subfloat[]{\includegraphics[width=0.5\textwidth]{figures/{TrigOpsPublicWinter2019_L1_single-item_rates_logscale_ATLASStyle_359872}.pdf}}
  \subfloat[]{\includegraphics[width=0.5\textwidth]{figures/{TrigOpsPublicWinter2019_HLT_group_rates_ATLASStyle_359872}.pdf}}
  \caption{Trigger rates for (a) L1 and (b) HLT or a typical run in September 2018. The overall rate (black dashed lines) is broken down into some main individual triggers. Figures sourced from~\cite{triggerpublic}.}
  \label{fig:ATLAS:trigger}
\end{figure}

The trigger broadly works by identifying detector objects that are likely to correspond to individual particles and thus indicate a hard scatter $pp$ interaction.
The rate of the trigger is controlled by specifying some energy threshold the detector object has to meet in order to be passed to the next trigger in the case of L1 or written to disk in the case of HLT.
The collection of trigger object definitions and corresponding energy thresholds is called the \textit{trigger menu}, and is set every year of data taking (with some minor changes between periods in the same year)~\cite{ATL-DAQ-PUB-2016-001,ATL-DAQ-PUB-2017-001,ATL-DAQ-PUB-2018-002,ATL-DAQ-PUB-2019-001} according to the instantaneous luminosity and pile-up conditions and physics objectives.

Trigger considerations are vital for any analysis, because if the physics being targeted by an analysis does not pass any trigger then the data are simply not stored and the analysis cannot be done.
For example, the low-mass extension of the search in Chapter~\ref{ch:HBSM} discussed in Appendix~\ref{ch:HBSM_lowmass_app} spends considerable effort on finding a suitable trigger for the new signature in that search; luckily, there is an existing trigger (intended for other uses) which does have efficiency on those new signals.
However, there are a few different kinds of triggers on the trigger menu which can enable analyses in light of the trigger limitations other than the \textit{primary} triggers, which store the entire event every time the trigger is fired.
Triggers can be \textit{prescaled}, meaning there is some probability $<1$ that the trigger fires, which allows for lower energy thresholds - these can be used for background or efficiency studies or simply for monitoring the beam, detector, or trigger systems.
Also, there are situations where the energy threshold is lowered but only small fraction of the total information in the event is stored - these can be used for detector calibration or to directly conduct \textit{trigger-level} analyses (e.g.~\cite{Aaboud:2018fzt}) to be sensitive to kinematic regions that would otherwise be inaccessible with the primary triggers.

There are also special runs with entirely different trigger menus than the regular physics menu.
For example, a \textit{minimum-bias} trigger is run as the only item on the trigger menu for a short period of time (i.e., trigger on every event with some minimum quality controls with some high prescale).
These minimum-bias events are used, among other things, for measuring online trigger efficiencies offline and for overlaying pile-up events on top of simulations (Section~\ref{sec:ATLAS:simulation}).

\subsection{Level 1 Trigger}
\label{sec:ATLAS:L1}

The L1 trigger has two major subsystems, one based on observations in the calorimeter (L1Calo) and one based on observations in the muon system (L1Muon).
There is also a topological trigger (L1Topo) which combines information from the two subsystems to make trigger decisions on a whole-event basis.
In particular, there is not enough time at L1 to reconstruct tracks from hits in the tracker.

L1Calo sets up $0.1\times0.1$ in $\Delta\eta \times \Delta\phi$ trigger towers in the calorimeter and forms \textit{regions of interest}, or \textit{RoIs}, to identify physics objects.
The electron/photon and tau triggers use $2\times2$ groupings of trigger towers in the EM calorimeter that are local maxima in energy, with additional isolation requirements in the surrounding towers and in the hadronic calorimeter.
The isolation requirements are intended to distinguish between isolated photons and collimated $\pi^0\rightarrow \gamma\gamma$ decays.
The jet triggers use $4\times4$ and $8\times8$ groupings of trigger towers in the EM and hadronic calorimeters with the central $2\times2$ grouping a local maximum in energy.
A schematic of the L1Calo trigger towers and RoIs can be seen in Figure~\ref{fig:ATLAS:L1Calo}.

\begin{figure}[htbp]
  \centering 
  \subfloat[]{\includegraphics[width=0.5\textwidth]{figures/{L1Calo}.pdf}}
  \caption{Schematic view of the trigger towers used as input to the L1Calo trigger algorithms. Figure sourced from~\cite{TRIG-2016-01}.}
  \label{fig:ATLAS:L1Calo}
\end{figure}

The L1Muon system uses the information from the RPCs and TGCs (Section~\ref{sec:ATLAS:MS}) to identify muon candidates in time to pass on to the HLT.

There is finally an L1Topo system which combines information from L1Calo and L1Muon to evaluate event-wide information, in particular the \textit{missing transverse energy} or \Etmiss{}, which corresponds to inbalances of momentum in the transverse plane (Section~\ref{sec:ATLAS:met}).

\subsection{High Level Trigger}
\label{sec:ATLAS:HLT}

As mentioned above, the HLT uses offline-like reconstruction algorithms to target a wide range of more specific physics goals than the L1.
In particular, tracking information from hits in the tracker, finer-granularity information in the calorimeter, and more precise measurements in the MS allow more precise reconstruction than is available at L1.

The tracking algorithms first run a fast tracking algorithm with rough pattern recognition\footnote{Not to be confused with the similarly-named but ultimately shuttered \textit{Fast TracKer}~\cite{Shochet:1552953}, or FTK, which was a project to implement tracking directly into the hardware in order to speed up performance.} within RoIs identified at L1.
These fast tracks are then used as seeds for an offline-like (Section~\ref{sec:ATLAS:tracks}) track reconstruction algorithm.

Calorimeter reconstruction algorithms are used to identify electrons, photons, taus, and jet candidates and finally \etmiss{} global reconstruction.
The first step is to construct clusters of energy in the calorimeter based on RoI seeds from L1, for which there are two different algorithms.

The electron and photon reconstruction algorithms use a sliding-window approach by finding a window of size $0.075 \times 0.175$ in $\Delta\eta \times \Delta\phi$ that is a local maximum of energy in projective towers.
The shower shape is then found by determining layer-by-layer in the calorimeter the center of energy of the cells behind the sliding window and summing up a fixed size window around that.
This shower shape is then used to positively identify electrons and photons, e.g. using the ratio of energy deposited in the hadronic calorimeter to the electromagnetic calorimeter.

The tau, jet, and \etmiss{} reconstruction algorithms use a global topo-clustering algorithm~\cite{Aad:2016upy} very similar to the offline reconstruction algorithm (Section~\ref{sec:ATLAS:clusters}), which are built up iteratively from high-energy cell seeds.
Jets are then reconstructed using the \antikt{} algorithm with $R=0.4$ or $R=1.0$ (Section~\ref{sec:jets:def}) using these clusters as seeds.
The jets are calibrated in a similar manner to the offline procedure (Section~\ref{sec:ATLAS:jet_calibration}).
Small-$R$ jets are calibrated in particular incorporating a pile-up subtraction step, an overall MC-based \pt{} correction (the exploration of which is the subject of Chapter~\ref{ch:NI}), and the global sequential calibration (GSC) (the improvement of which is the subject of Chapter~\ref{ch:GenNI}).
Large-$R$ jets in 2017 and 2018 are trimmed and have a mass cut, but do not use any other jet substructure techniques (Section~\ref{sec:jets:tagging}) for identifying boosted massive objects.

Tau identification uses similar principles to the offline selection (Section~\ref{sec:ATLAS:EM}), looking for small-$R$ jets with narrow calorimeter energy deposits and low numbers of associated tracks.

Jets originating from $b$-quarks can also be tagged (Section~\ref{sec:ATLAS:btagging}), by identifying secondary vertices off the beamline that are characteristic of such jets.
In order to judge if a secondary vertex is significantly far enough from the beamline, it is essential to have a precise measurement of the \textit{beamspot}, which is the 3-dimensional ellipsoidal region in which $pp$ collisions can occur\footnote{With roughly a multivariate Gaussian probability distribution.}~\cite{ATLAS-CONF-2010-027}.
The Author has contributed to a project intended to more precisely measure the online beamspot using Bayesian inference~\cite{beamspot}, which could improve the $b$-tagging at HLT.

As jets with no such tagging are the most generic detector objects formed in ATLAS, the rate of jet production is very high - e.g., the cross section of producing a jet with $\Et>100$ GeV is at least a factor of $10$ higher than any other ``interesting'' electroweak process (Figure~\ref{fig:ATLAS:xs}).
Therefore, the energy thresholds for jets in the trigger are the highest of any other object, and analyses using only jet triggers are therefore limited to very high energies.
For example, the search in Chapter~\ref{ch:CWoLa} uses a single jet trigger, corresponding to offline $\pt>500$ GeV; this limits the minimum dijet invariant mass $m_{JJ}>1.1$ TeV just to meet the trigger requirements.
Because of these high requirements, there have been concerted efforts for trigger-level analyses using lower \pt{} jets~\cite{Aaboud:2018fzt}.

There are a variety of different trigger algorithms for \etmiss{}, but the most basic algorithm sums up the $\vec{\pt}$ (including the direction in the transverse plane) of all cells in the calorimeter to find any imbalance.
Other algorithms build on this by adding pile-up corrections or jet-based or topo-cluster-based associations.

The muon reconstruction algorithm first runs a fast algorithm which then seeds RoIs to be used in a precision step similar to the offline algorithm (Section~\ref{sec:ATLAS:muons}).
The fast algorithm matches the RoIs identified at L1Muon to data from the MDT chambers (Section~\ref{sec:ATLAS:MS}) to form tracks in the MS.
These tracks are then back-extrapolated back to the interaction point and combined with tracks in the inner detector.
The precision step basically repeats this process with a refined track-finding and \pt{} measurement, with an additional step of extrapolating tracks from the inner detector to hits in the MS in case the back-extrapolation fails.
Dimuon triggers (with dimuon mass requirements) are also used for tagging $b$-hadrons, e.g. $\Upsilon(1S)\rightarrow \mu\mu$ and intermediate decays involving $J/\psi\rightarrow \mu\mu$.

Finally, there are dedicated triggers with low rates for exotic signatures, e.g. long-lived particles~\cite{Aad:2013txa}.

\section{Object Reconstruction}
\label{sec:ATLAS:objects}
Events passing the triggers (Section~\ref{sec:ATLAS:trigger}) are written to disk and the detector observables are \textit{reconstructed} with algorithms into objects intended to correspond to particular physics particles.
Tracks derived from hits in the inner detector (Section~\ref{sec:ATLAS:tracks}) and topological clusters of cells in the calorimeter (Section~\ref{sec:ATLAS:clusters}) are used to build up objects corresponding to photons and electrons (Section~\ref{sec:ATLAS:EM}) and jets (Section~\ref{sec:ATLAS:jets}).
Muons are also reconstructed using inormation from the MS (Section~\ref{sec:ATLAS:muons}).
Finally, these objects are combined together to estimate the missing transverse energy (Section~\ref{sec:ATLAS:met}).

\subsection{Tracks}
\label{sec:ATLAS:tracks}
Tracks, corresponding to the paths of charged particles in the inner detector, are reconstructed from hits in the various layers of the tracker~\cite{ATL-PHYS-PUB-2015-018,Aaboud:2017all}.
An example event display showing hits in the inner detector and the tracks formed from those hits can be seen in Figure~\ref{fig:ATLAS:tracks}.
\begin{figure}[htbp]
  \centering 
  \subfloat[]{\includegraphics[width=0.5\textwidth]{figures/{JiveXML_264034_11475271_2}.png}}
  \caption{Event display showing hits in the inner detector and the tracks formed from those hits. Figure source~\cite{Collaboration:2014666}.}
  \label{fig:ATLAS:tracks}
\end{figure}

Hits in the pixel (including the IBL) and SCT layers are clustered in order to account for a single particle passing through multiple adjacent pixels or multiple particles passing through the same or adjacent pixels; these clusters are then abstracted as three-dimensional \textit{space-points}.
Track seeds are then formed from sets of three space-points.
A combinatorial Kalman filter~\cite{Fruhwirth:1987fm} is then used to incorporate additional space-points from other layers of the pixel and SCT detectors which are compatible with the particle trajectory into a track candidate.
An ambiguity solver is then used to identify clusters with track candidates, using a neural network to identify and predict merged clusters resulting from multiple tracks~\cite{Aad:2014yva}.
The clusters are identified with the track candidates in order of quality of the track, considering criteria like the number of holes (missing clusters) across the layers and $\chi^2$ of the track fit.
Track candidates are also rejected if they do not meet basic requirements like $\pt>400$ MeV (in which case the particle's trajectory would curve so much in the magnetic field it would never leave the inner detector).
Finally, a track fit is performed using all available information (in particular including information from the TRTs) to determine the track momentum (measured directly as the charge to momentum ratio $q/p$) and direction, transverse impact parameter off the beamline $d_0$ (i.e., the closest approach of the track trajectory to the beamline), and longitudinal displacement along the beamline $z_0$ (at the point of closest approach).
The tracking reconstruction is particularly difficult within the dense environments of jets, where there can be large numbers of tracks in a small region.

The resolution of track $q/p$, $d_0$, and $z_0$ as a function of $\pt$ can be seen in Figure~\ref{fig:ATLAS:track_resolution}.
\begin{figure}[htbp]
  \centering 
  \subfloat[]{\includegraphics[width=0.5\textwidth]{figures/{track_p_resolution}.png}}\\
  \subfloat[]{\includegraphics[width=0.5\textwidth]{figures/{track_d0_resolution}.png}}
  \subfloat[]{\includegraphics[width=0.5\textwidth]{figures/{track_z0_resolution}.png}}
  \caption{Track resolution of (a) $q/p$, (b) $d_0$, and (c) $z_0$ as a function of $\pt$ in cosmic-ray data. The measurements are compared among tracks measured with silicon-only components, full inner detector, and full inner detector in simulation. Figures sourced from~\cite{Aad:2010bx}.}
  \label{fig:ATLAS:track_resolution}
\end{figure}
The momentum resolution is quite good, around $1\% \oplus 0.05\% * \pt/\text{GeV}$ - the momentum resolution gets worse at high momentum as the track has less curvature in the magnetic field.
The $d_0$ resolution is important for constructing secondary vertices, which is essential for $b$-tagging (Section~\ref{sec:ATLAS:btagging}).
The $z_0$ resolution is important for constructing primary vertices which correspond to interactions along the beamline.

\subsubsection{Primary Vertices}
Primary vertices~\cite{Aaboud:2016rmg,ATL-PHYS-PUB-2015-026,Meloni:2016sag} are collections of tracks emanating from a single point indicating a $pp$ interaction at that point.
The average number of interactions per bunch crossing $\mu$ is $>1$, which is directly related to the instantaneous luminosity; $\mu>1$ is the cause of pile-up interactions in the event other than the \textit{hard-scatter} interaction or (roughly) the one that caused the event to pass the trigger.
In the ideal case the expected number of reconstructed primary vertices would scale linearly with $\mu$; however, the dominant cause of nonlinearity is vertex merging due to the high density of interactions in the luminous region.
There can also be vertex splitting, vertex fakes, and inefficiencies in vertex reconstruction.

The vertex reconstruction algorithm proceeds iteratively - after choosing a vertex seed, the algorithm alternates between finding tracks compatible with coming that vertex (subject to their $z_0$ and $d_0$ resolutions) and re-fitting the vertex position with the associated tracks until some stopping condition is met (vertices must have at least $2$ associated tracks).
The found vertex and its associated tracks are then removed from consideration and the process is repeated until all tracks are associated to a vertex or no more vertices can be found.
The output of this algorithm is a set of vertex positions and the covariance matrix of their resolutions.

The efficiency of vertex reconstruction as a function of number of associated tracks can be seen in Figure~\ref{fig:ATLAS:vertexa}.
\begin{figure}[htbp]
  \centering 
  \subfloat[]{\includegraphics[width=0.5\textwidth]{figures/{ATLAS_vertex_efficiency}.png}\label{fig:ATLAS:vertexa}}
  %\subfloat[]{\includegraphics[width=0.33\textwidth]{figures/{ATLAS_vertex_x_resolution}.png}\label{fig:ATLAS:vertexb}}
  %\subfloat[]{\includegraphics[width=0.33\textwidth]{figures/{ATLAS_vertex_y_resolution}.png}\label{fig:ATLAS:vertexc}}
  \subfloat[]{\includegraphics[width=0.5\textwidth]{figures/{ATLAS_vertex_z_resolution}.png}\label{fig:ATLAS:vertexd}}
  \caption{(a) Efficiency of vertex reconstruction as a function of number of associated tracks. Also, resolution of vertices in (b) $x$, (c) $y$, and (d) $z$. Measured in low-$\mu$ ($\mu\sim 0.01$) data and in MC. Figures sourced from~\cite{ATL-PHYS-PUB-2015-026}.}
  \label{fig:ATLAS:vertex}
\end{figure}
The vertex reconstruction efficiency is basically $1$ when the vertex has $5$ or more associated tracks.
Figure~\ref{fig:ATLAS:vertexd} shows the $z$ resolution of the primary vertices.
The $z$ resolution is important for distinguishing between different interactions along the beamline.

The primary vertex with the highest $\sum \pt^2$ over the associated tracks is designated as the \textit{hard-scatter} vertex (and the associated tracks are considered to be the hard-scatter tracks), as it corresponds to the hardest interaction in the event and therefore the most likely to be ``interesting''.
The remaining vertices and their associated tracks are labeled \textit{pile-up}.
For most reconstruction algorithms considered below, if they use tracks, only the hard-scatter tracks are considered.
However, the pile-up tracks are used for the removal of calorimeter jets originating from pile-up interactions, as the calorimeter by itself does not have nearly good enough angular information to distinguish between energy clusters due to hard-scatter and pile-up interactions.
Also, tracks with large impact parameters, but within some small distance of the hard-scatter primary vertex, are used to reconstruct secondary vertices for $b$-tagging.

\subsection{Clusters}
\label{sec:ATLAS:clusters}



\subsection{Photons and Electrons}
\label{sec:ATLAS:EM}

\subsection{Jets}
\label{sec:ATLAS:jets}
Detector-level (`reco') jets are formed from topologically connected, noise-suppressed calorimeter cell-clusters~\cite{Aad:2016upy} at the electromagnetic scale using the FastJet~\cite{Cacciari:2011ma} implementation of the \antikt jet algorithm~\cite{Cacciari:2008gp} with distance parameter $R = 0.4$.   The angular coordinates of the cell-clusters are corrected to point to the location of the $pp$ collision instead of the geometric center of the detector.  

\subsubsection{Jet Calibration}
\label{sec:ATLAS:jet_calibration}
Hadron-level (`truth') jets are formed from detector-stable simulated particles ($c\tau > 10$ mm), excluding muons and neutrinos.  Reco jets are geometrically matched to truth jets using the $\Delta R$ distance metric; all jets with a reco-truth match are considered.  Truth jets are matched to partons using ghost association~\cite{Cacciari:2008gn}; the type of the highest energy parton matched to a truth jet is used as the label. 

The goal of jet calibration is to ensure that the average calibrated detector-level momentum is the same as the corresponding particle-level quantity on average: $f(x)\equiv\langle p_\text{T}^\text{reco}|p_\text{T}^\text{true}=x\rangle\approx x$.  In practice, since $p_\text{T}^\text{reco}|p_\text{T}^\text{true}$ is not exactly normal, a Gaussian function is fit to the core of the probability distribution and the mean and standard deviation of the fit are used to quantify the bias and spread.  A related quantity to $f(x)$ is the average response $R(x)=f(x)/x$.  The closure of the jet calibration procedure is often quantified by the deviation of $R(x)$ from unity.

The calibration procedure is achieved through a series of steps.
Following jet reconstruction from the calorimeter cell-clusters, the impact of multiple nearly simultaneous $pp$ collisions (pile-up) is corrected for using a jet area-based~\cite{Cacciari:2007fd,Cacciari:2008gn} approach with a residual correction sensitive to both in-time and out-of-time pile-up~\cite{Aad:2015ina}.
Following the pile-up correction, a calibration for the jet energy brings $E^\text{reco,calibrated}\approx E^\text{true}$.
This absolute MC-based calibration also corrects the jet direction.
After this calibration is applied, the GSC corrects the dependence of the jet $p_\text{T}$ on various jet quantities using information from the tracker, calorimeter, and MS (see Section $5.3$ in~\cite{PERF-2016-04} for the detailed list).
This reduced dependence makes the response more similar for quark and gluon jets, reduces the uncertainty due to jet fragmentation modeling for a given jet type, and improves the jet energy resolution.
The final step of the jet calibration procedure applied only to data is an in-situ correction that accounts for the residual difference in $R$ between data and simulation.
Complete details about the ATLAS jet calibration procedure can be found in~\cite{PERF-2016-04,Aad:2011he}.  

\subsubsection{$b$-Tagging}
\label{sec:ATLAS:btagging}

\subsubsection{Taus}
\label{sec:ATLAS:taus}

\subsection{Muons}
\label{sec:ATLAS:muons}

\subsection{Missing Energy}
\label{sec:ATLAS:met}
