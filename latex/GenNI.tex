\section{Abstract}
Jets that are reconstructed by the ATLAS detector are corrected to ensure that the reported energy is an unbiased measurement of the particle-level jet energy.
This jet energy scale correction consists of multiple steps where features of the reconstructed jet are used sequentially, in order to improve the resolution and reduce the differences between quark and gluon jets (flavor dependence).
This Chapter reports on a new method based on multivariate regression, demonstrated with neural networks, that generalizes the current (iterated) one-dimensional technique for performing jet energy scale corrections (numerical inversion), called \textit{generalized numerical inversion}.
The results presented in this Chapter are published in~\cite{ATL-PHYS-PUB-2018-013}.
The new method remains an unbiased measurement of the particle-level energy, but allows for simultaneously using multiple features, such as the number of tracks inside jets and the average track radius, in order to account for correlations in the dependencies between features and with the jet energy.
This new procedure can further improve the jet energy resolution and flavor dependence beyond a sequential approach and can be systematically improved by exploiting more variables and their interdependence with the jet energy response.

\section{Introduction}
\label{sec:GenNI:intro}
%-------------------------------------------------------------------------------
%Jets are collimated sprays of particles resulting from the fragmentation of high energy quarks and gluons.
The two searches presented in this Thesis (Chapter~\ref{ch:HBSM} and Chapter~\ref{ch:CWoLa}) use jets extensively, and besides that nearly every analysis at the Large Hadron Collider (LHC) uses jets in some capacity, both Standard Model (SM) measurements and searches for physics beyond the SM.
All of these analyses rely on an accurate and precise measurement of the jet energy.
As mentioned in Section~\ref{sec:ATLAS:jet_calibration}, due to various distortions arising from detector effects, the reconstructed jet energy deviates from the particle-level jet energy in the absence of a detector.
These distortions are corrected for using a series of calibration steps~\cite{PERF-2016-04,Aad:2011he}.
All of these steps proceed ultimately via numerical inversion, the properties of which are expounded upon in detail in Chapter~\ref{ch:NI}.
This Chapter is concerned with improving one particular and important part of the current calibration procedure, the Global Sequential Calibration (GSC).
This step incorporates auxiliary measurements about the jet, such as its reconstructed charged particle multiplicity, to improve the overall quality of the energy reconstruction~\cite{ATLAS-CONF-2015-002}.
In particular, the calibration is designed to reduce the dependence of the reconstructed energy on jet and event features.
%As a result, the size of the residual distortions decreases for different final states and the dependence on an accurate model of jet features is reduced.  
The intention of this step of the calibration is to reduce the dependendence of the jet energy on the final state being used in analysis and on the model of the jet features being used to derive the correction.

%The current scheme for incorporating auxiliary information treats the impact of each feature on the residual jet energy distortions as independent and thus proceeds as a sequential calibration.  This approach works well for the current set of features, which are chosen to satisfy the independence criteria.  However, there is more information about the jet that is available and using these data in a sequential way would be sub-optimal.  In addition, advances in machine learning for jets~\cite{Larkoski:2017jix} have shown that neural networks and other modern tools can exploit subtle correlations in high dimensions to improve performance.  This chapter describes the connection between these two concepts by demonstrating a machine learning approach to a jet calibration that uses auxiliary features.  In order to ensure that this machine learning approach has the same properties as the algorithm used by the standard calibration scheme~\cite{Cukierman:2016dkb}, a new technique called \textit{Generalized Numerical Inversion} is described.  The main advantage of this algorithm, unlike traditional machine learning regression algorithms, is that it is independent of the energy spectrum of jets used for training.  By including all of the available information at once, one can test the importance of correlations in the auxiliary features with the residual energy distortions and ultimately improve the quality of the calibration overall. 
The current method for the GSC treats the impact of each auxiliary feature sequentially and independently, which requires the set of features used in the correction to be chosen in such a way to have uncorrelated effects on the jet energy.
However, there is additional information available which could improve the calibration and yet is not used in the current GSC because of this requirement of uncorrelation.
This Chapter presents a new technique using neural networks to simultaneously take into account multiple auxiliary variables in this correction which may or may not have correlated effects on the jet energy.
The technique relies both on the general capacity of neural networks to approximate well complicated functions in high dimensions~\cite{HORNIK1991251} and on recent advances in jet substructure~\cite{Larkoski:2017jix} which indicate useful features for applying this correction.
As mentioned in Chapter~\ref{ch:NI}, it is important that the calibration is independent of the underlying spectrum, and therefore that ultimately it relies on numerical inversion.
The new technique presented here, called \textit{Generalized Numerical Inversion}, incorporates neural networks into the numerical inversion framework in order to accomplish both goals of simultaneously taking into account the effect of multiple auxiliary variables and of remaining independent of the underlying spectrum.
Ultimately this technique is shown to improve the overall quality of the jet calibration.

This Chapter is organized as follows.
Section~\ref{sec:GenNI:atlas} discusses the simulated samples used in this study and Section~\ref{sec:GenNI:jetreco} briefly reviews the GSC and describes it in the notation used in this Thesis.
Generalized numerical inversion is described in Section~\ref{sec:GenNI:genni} and first results using this new method are presented in Section~\ref{sec:GenNI:results}.
The chapter closes with Section~\ref{sec:GenNI:conclusion}.

%-------------------------------------------------------------------------------
%\section{ATLAS Detector and Event Simulations}
\section{Event Simulations}
\label{sec:GenNI:atlas}
%-------------------------------------------------------------------------------

Studies documented within this chapter are performed using a variety of Monte Carlo (MC) simulated samples.
Dijet events are generated at Leading Order (LO) in \PYTHIA 8.1~\cite{Sjostrand:2007gs} with the $2 \rightarrow 2$ matrix element convolved with the NNPDF2.3LO Parton Distribution Function (PDF) set~\cite{Ball:2012cx} and using the A14 set of tuned parameters~\cite{ATL-PHYS-PUB-2014-021}.
An additional sample is simulated using \textsc{Herwig} 7.0~\cite{Bellm:2015jjp} using the NNPDF3.0 NLO PDF and the default set of tuned parameters for the underlying event.
Both \PYTHIA and \textsc{Herwig} are interfaced with \textsc{EvtGen} for heavy flavor decays~\cite{Lange:2001uf,ATL-PHYS-PUB-2014-008}.

%Additional dijet events are simulated using different generators, in order to study the impact of modeling uncertainties. \SHERPA 2.1~\cite{Gleisberg:2008ta} generates events using multi-leg $2\rightarrow N$ matrix elements, which are matched to parton showers following the CKKW prescription~\cite{Catani:2001cc}. These \SHERPA events are simulated using the CT10 PDF set~\cite{Lai:2010vv} and default \SHERPA event tune. \HERWIGpp 2.7~\cite{Bahr:2008pv,Corcella:2000bw} provides a sample of events where additional radiation is showered using angular-ordering. These events are generated with the $2\rightarrow 2$ matrix element, convolved with the CTEQ6L1PDF set~\cite{Pumplin:2002vw} and configured with the UE-EE-5 tune~\cite{Gieseke:2012ft}.

%mc16_13TeV.364446.Herwig7EvtGen_H7UE_NNPDF30nlo_jetjet_JZ3.deriv.DAOD_STDM9.e5989_s3126_r9364_r9315_p3306)

All simulated events have been reconstructed using a full simulation of the ATLAS detector~\cite{SOFT-2010-01} implemented in \GEANT 4~\cite{Agostinelli:2002hh}, which describes the interactions of particles with the detector and the subsequent digitization of analog signals.
The effects of multiple simultaneous $pp$ collisions (pile-up) are simulated with minimum bias $pp$ collisions using \PYTHIA 8.1 and overlaid on the nominal dijet interactions.

%-------------------------------------------------------------------------------
\section{Global Sequential Calibration}
\label{sec:GenNI:jetreco}
%-------------------------------------------------------------------------------
As mentioned in Section~\ref{sec:ATLAS:jet_calibration}, the ATLAS jet calibration proceeds via multiple steps.
The largest correction is the absolute MC-based correction which brings the overall scale of the reconstructed jet \ET{} to the truth or particle-level \ET{}.
The step immediately proceeding is the GSC, which corrects the dependence of the jet \pt{} on various jet quantities derived from information in the tracker, calorimeter, and muon system~\cite{PERF-2016-04}.
The goal of this correction is to make the response more similar between quark- and gluon-initiated jets, and furthermore reduces the uncertainty due to jet fragmentation modeling for a given jet type.
%The focus of this Chapter is on improving the method used for the MC-based residual calibration of the jet $p_\text{T}$ on various jet quantities following an inclusive calibration, which in ATLAS is accomplished with the GSC.

%To perform a calibration in $\pt$, one may want to learn a function that predicts $\pttrue$ given $ \ptreco$.
%While straightforward, this method depends on the distribution of $p_\text{T}^\text{true}$ and thus renders the calibration dependent on the event sample from which it is derived.
%Moreover, this method does not guarantee that $f(x) \approx x$ even for the sample used to derive the calibration.
%After applying the learned function it should be the case that $p_\text{T}^\text{reco}\approx \langle p_\text{T}^\text{true}|p_\text{T}^\text{reco} \rangle$, but $f(x) = \langle p_\text{T}^\text{reco}|p_\text{T}^\text{true}=x\rangle\approx x$ may not necessarily be satisfied.
%%In particular, it may be the case that $f(x)\approx x$ for the sample used for deriving the calibration, but $f(x)\neq x$ (non-closure) for other samples. %Impossible...if f(x)=x for one sample then it's true for all samples, that's the point.
%A potential modification of the naive procedure is to enforce that the distribution of $p_\text{T}^\text{true}$ used in the learning is uniform over a particular range.
%However, one can show that if $f(x)$ is nonlinear or if the resolution $\sigma( p_\text{T}^\text{reco}|p_\text{T}^\text{true})$ is nonconstant, then even with this modification there can be large non-closures.
%Since both of these properties are true of jet reconstruction in ATLAS, this simple fix does not solve the non-closure problem.
%
%An approach that can be used to ensure that the calibration is independent of the $p_\text{T}^\text{true}$ distribution is called numerical inversion, which is the method used in ATLAS for the jet energy corrections.  Instead of learning to predict
%%\footnote{As stated above, the inclusive calibration actually corrects the jet energy; for simplicity and because the focus of this chapter is about improving the GSC that corrects the $p_\text{T}$, only the transverse momentum is mentioned here.} 
%$p_\text{T}^\text{true}$ given $p_\text{T}^\text{reco}$, numerical inversion does exactly the opposite - by using $f(x)$ directly, $p_\text{T}^\text{reco}$ is calibrated via $p_\text{T}^\text{reco}\mapsto \ptrecohat \equiv f^{-1}(p_\text{T}^\text{reco})$.  This procedure is inherently independent of the distribution of $p_\text{T}^\text{true}$ and under a wide variety of circumstances~\cite{Cukierman:2016dkb}, the response closes ($\hat{R}(x)\equiv\langle \ptrecohat/\pttrue|p_\text{T}^\text{true}=x\rangle\approx 1$) following the calibration.  

There may be a little confusion here in moving from the calibration of \Et{} to \pt{}.
The first thing to note is that this is just simply how the ATLAS calibration does it, first an absolute correction to \Et{} and then following a residual correction to \pt{}.
The second thing to note is that \Et{} and \pt{} have a well-defined relation: $\Et=\sqrt{\pt^2+m^2}$, where $m$ is the mass of the jet.
The GSC is only applied to small-$R$ jets, intended to apply to quark- and gluon-initiated jets in which the true mass is either $0$ or much less than the \pt{} (the lowest \pt{} in the calibration is 20 \GeV, while the highest quark mass reconstructed in a small-$R$ jet is the bottom quark, with mass of $\sim4$ \GeV).
This is related to the fact that the opening angle of a jet is generically roughly $\Delta R \sim \frac{2m}{\pt}$~\cite{Shelton:2013an}; for a small-$R$ jet, with $\Delta R$ parameter of 0.4, $\frac{m}{\pt}<0.2$.
Because of the negligibility of this term, for small-$R$ jets it is the case that $\Et\sim\pT$, and the term ``jet energy'' correction is used somewhat loosely in this Chapter (and in the previous one) to refer to the ATLAS jet \Et{} and \pT{} corrections in the calibration.
Generally the distinction is not important, but where it is the text is clear about what is being corrected.

For large-$R$ jets, the $\Delta R$ parameter is $1.0$, allowing for jets with larger ratios of $\frac{m}{\pt}$.
The GSC is not applied to these jets, but rather after the inclusive \Et{} correction an energy-dependent mass calibration is applied (Section~\ref{sec:ATLAS:jet_calibration}).
The Author has contributed to work which directly uses the techniques developed in this Chapter to employ neural networks to simultaneously calibrate the mass and energy of large-$R$ jets~\cite{ATL-PHYS-PUB-2020-001}.

As mentioned in Chapter~\ref{ch:NI}, after the inclusive correction it is approximately true that $f(x)\equiv \langle p_\text{T}^\text{reco}|p_\text{T}^\text{true}=x\rangle = x$\footnote{In practice $f(x)$ is measured using the mode of the distribution rather than the mean.} (Equation~\ref{eqn:NI:closure_mode_text}), i.e. that the calibration closes and that the average reconstructed or detector-level jet \pt{} ($p_\text{T}^\text{reco}$) is equal to the truth or particle-level \pt{} ($p_\text{T}^\text{true}$) when conditioning on the truth \pt{}.
\footnote{Of course, this statement is subject to the stipulations mentioned in that Chapter, and in fact a major result from that study was understanding exactly how and why the calibration \textit{does not} close. However, ultimately the understanding from that study was that the major non-closures would be a bigger issue at higher pile-up conditions that will exist at the LHC in the future.}
The reason to follow this with the GSC is that even though the overall response closes, $f(x)$ may have a residual dependence on auxiliary information available from the detector, such as the jet radiation pattern and the energy deposition pattern in the detector.
Let $\theta$ represent the available auxiliary information about a jet.
Then, the function $f$ can be generalized as $f_\theta(x)\equiv \langle p_\text{T}^\text{reco}|p_\text{T}^\text{true}=x,\theta\rangle$.

%Although it may seem intuitive that one would want to correct for the dependence of the jet energy on auxiliary variables if such a dependence exists, it is worth delving into exactly what the reasons and implications of such a correction are.

In general, if it is found that the jet energy $f_\theta(x)$ depends on some auxiliary variable $\theta$, then it is desirable that the calibration removes this dependence, for a few reasons.
First, if $\theta$ is not well-modeled by the simulation then even though there may be closure in the simulation there may not be closure in the data, and this could introduce systematic uncertainties in the final calibration.
Second, if the distribution of $\theta$ is sample-dependent, e.g. correlated with the jet originating parton, then there could be closure in one sample but not another, which could cause nonoptimal selections in the final analysis cuts.
Third, there is a degradation of the resolution $\sigma(x)$ due to the spread of $\theta$, which again can cause the sensitivity of final analysis cuts to be worse.
These are the three metrics by which we judge the performance of the GSC and of generalized numerical inversion in this Chapter.

However, this third point is more subtle than it naively appears.
While it is true that there is a degradation of the resolution due to the spread of $\theta$, it is \emph{not} the case that the resolution always gets better when the dependence of the response on an auxiliary variable is corrected.
In particular, there exist certain situations where correcting for the dependence of the response on an auxiliary variable can actually make the resolution worse.
These situations are explored in Appendix~\ref{sec:GenNI_app:auxiliary}.

It is important to note that this auxiliary information $\theta$ is available at the detector or reconstructed level.
Therefore, while $f_\theta(x)$ is derived in simulation, for a given jet at detector level $\theta$ is known and $f_\theta(x)$ can be inverted as usual across its argument to give the calibration function.
For $\theta\in\mathbb{R}$, the correction is therefore given by $p_\text{T}^\text{reco}\mapsto \ptrecohat = f_\theta^{-1}(p_\text{T}^\text{reco})$.
In practice, the distribution of $\theta$ is binned and the numerical inversion is performed for different functions in each bin of $\theta$.


When $\theta\in\mathbb{R}^n$, the GSC proceeds with a sequential (as the name suggests) application of numerical inversion:

\begin{align}
\label{eqn:GenNI:gsc}
p_\text{T}^\text{reco}\mapsto \ptrecohat = f_{\theta_{n}}^{-1}\left(\cdots f_{\theta_{2}}^{-1}\left(f_{\theta_{1}}^{-1}\left(p_\text{T}^\text{reco}\right)\right)\cdots\right).
\end{align}

%Note that Eq.~\ref{eq:gsc} assumes that $f_{\theta_{i}}(x)$ is independent of $\theta_{j\neq i}$; otherwise, there will be a residual dependence on $\theta_i$ after the sequential calibration is applied.
The sequential method removes all residual dependencies when $f_{\theta_{i}}(x)$ is independent of $\theta_{j\neq i}$, i.e. when $f_{\theta}(x)$ is entirely determined by one feature at time.
If there are such dependencies of $f_{\theta}(x)$ on more than one feature $\theta_i$, then there could be residual dependencies on some combination of the $\theta_i$ after the full sequential correction.

%-------------------------------------------------------------------------------
\section{Generalized Numerical Inversion}
\label{sec:GenNI:genni}
%-------------------------------------------------------------------------------

The idea of generalized numerical inversion is to simply replace the sequential approach in Equation~\ref{eqn:GenNI:gsc} with a single inversion: $p_\text{T}^\text{reco}\mapsto \ptrecohat = f_{\theta_1,...,\theta_n}^{-1}(p_\text{T}^\text{reco})$.  Binning the response in $n$ dimensions would require significant computing resources and so is practically infeasible.  An unbinned approach that can simultaneously capture the dependence on many features is needed to exploit the potential correlations in the response on the $\theta_i$.  One powerful tool for this purpose is a neural network.  In principle, neural networks can approximate any smooth function~\cite{Cybenko1989,HORNIK1991251} and have been shown to provide excellent performance for a wide variety of classification and regression tasks with limited training data.  Inverting a neural network can be non-trivial, so the procedure for generalized numerical inversion is adapted as follows:

\begin{enumerate}
  \item Learn a neural network approximation $L(x,\theta)$ to the function $f_\theta(x)=\langle p_\text{T}^\text{reco}|p_\text{T}^\text{true}=x,\theta\rangle$.  \\\ Note that $L(x,\theta):\mathbb{R}^{n+1}\rightarrow\mathbb{R}$.
\item Learn a neural network $C(L(x,\theta),\theta)$ that tries to predict $x$ given $\theta$ and $L(x,\theta)$.  This is an approximation to the family of functions $f^{-1}_\theta(x)$.  Note that learning the inverse this way is technically simple since $L$ is single-valued.
\item Calibrate with $\ptreco \mapsto \ptrecohat = C(\ptreco,\theta)$.  The calibration non-closure is defined as usual as the deviation of $\langle \ptrecohat/\pttrue | \pttrue=x,\theta\rangle$ from $1$.
\end{enumerate}

There are therefore two learning stages in this procedure.
The first step learns a neural network that predicts the average behavior of $p_\text{T}^\text{reco}$ given $p_\text{T}^\text{true}$ and $\theta$ while the second network tries to approximate a single-valued function.
In principle, the above procedure could be applied to the entire jet calibration procedure described in Section~\ref{sec:ATLAS:jet_calibration}, but the focus here is on the component addressing residual dependencies, following the inclusive jet energy calibration.

%-------------------------------------------------------------------------------
\section{Results}
\label{sec:GenNI:results}
%-------------------------------------------------------------------------------

To illustrate the potential of generalized numerical inversion, an example is provided using jets simulated with the ATLAS full detector simulation.  Neural network training is performed using scikit-learn~\cite{scikit-learn} with a simple two-layer feed-forward neural network that has 100 hidden nodes in each layer and a rectified linear unit activation function.  To lay the groundwork for application to the full GSC, two key jet features are studied: the number of tracks above 1 GeV associated to the jet ($n_\text{track}$) and the average track radius\footnote{The GSC currently used in ATLAS uses instead the track width, which is the average track radius multiplied by $(n_\text{track}+1)$.  The residual dependence of the $n_\text{track}$-calibrated response on the track width is negligible and is thus not useful for benchmarking generalized numerical inversion as the sequential calibration is nearly the same as the simultaneous calibration. 
  %There are observables which blah.
}:
\[
\Rtrack \equiv
\begin{cases}
  \frac{1}{n_\text{track}+1}\sum_\text{tracks}(p_\text{T,track}/\sum_\text{tracks'} p_\text{T,track'})\times \Delta R_\text{track,jet} & \text{if $\ntrack>0$}\\
  -1 & \text{if $\ntrack=0$}
\end{cases}
\]
These observables are useful because the calorimeter response depends on the type of parton that initiated the jet as gluon jets have more particles and have a wider radiation pattern than quark jets.  These properties lead to a different response because of the non-linear calorimeter-cell response as well as out-of-cone effects.  Even though it is only sensitive to charged particles, the tracker is insensitive to pile-up and is an excellent detector for measuring these jet radiation properties.

Figure~\ref{fig:GenNI:R_scan} shows the dependence of the response (following the inclusive energy calibration) on $n_\text{track}$ and $\Rtrack$.  The response depends strongly on these two quantities, varying by about  20-30\% across the accessible range.  The trends are also not uniform in jet $p_\text{T}$ - the response of lower $p_\text{T}$ jets shows a stronger dependence on both $n_\text{track}$ and $\Rtrack$.
%While the dependence of the response on $\Rtrack$ is non-linear, the residual dependence as shown in Fig.~\ref{fig:GenNI:R_scan}(a) is approximately linear and so is well-characterized by $dR/dn_\text{track}$.  

%Should describe the NN setup here before presenting results.  Figure~\ref{fig:GenNI:R_scan} shows the dependence of $f(x)$ on $n_\text{track}$ in several bins of true jet $p_\text{T}$.  Continue to describe the results from \href{https://indico.cern.ch/event/718661/contributions/2960406/attachments/1629909/2597628/GenNI_4.10.18.pdf}{This recent JES/JER talk}.


In order to understand the performance provided by a simultaneous instead of a sequential approach, approximations are derived for the calibration functions $f_{\text{n}_\text{track}}(x)$, $f_{\Rtrack}(x)$, and $f_{\text{n}_\text{track},\Rtrack}(x)$, and the sequential calibration $f^{-1}_{\Rtrack}(f^{-1}_{\text{n}_\text{track}}(p_\text{T}^\text{reco}))$ is compared with the simultaneous calibration $f^{-1}_{\text{n}_\text{track},\Rtrack}(p_\text{T}^\text{reco})$.
The sequential calibration presented here differs in some details with the standard GSC used in ATLAS; a major difference is that the calibration presented here does an unbinned fit to $\ptreco$ and the feature $\theta$ while the GSC does a binned fit which is then smoothed.
To control for this ability of the neural network to operate unbinned, the generalized numerical inversion approach is used for both the one- and two-feature cases in order to study only the differences between the sequential and the simultaneous calibrations.  
However, importantly the sequential approach demonstrated here does no worse than the GSC in correcting for the residual dependence of the response.

%The learned functions in the sequential calibration, $L(\pttrue,\text{n}_\text{track})/\pttrue$ and $L(\pttrue,\Rtrack)/\pttrue$, are presented in Figure~\ref{fig:GenNI:ntrack_wtrackmod_seq_LR_CR_scan}(a) and (d).
The learned functions $L$ in the sequential calibration are presented in Figure~\ref{fig:GenNI:ntrack_wtrackmod_seq_LR_CR_scan}(a) and (d).
As expected, Figure~\ref{fig:GenNI:ntrack_wtrackmod_seq_LR_CR_scan}(a) looks similar to Figure~\ref{fig:GenNI:R_scan}(a), as the neural network has learned to approximate the shape of the response with respect to $\ntrack$ (Figure~\ref{fig:GenNI:ntrack_wtrackmod_seq_LR_CR_scan}(d) is not expected to look similar to Figure~\ref{fig:GenNI:R_scan}(b), since the previously applied $\ntrack$ correction affects the dependence of the response on $\Rtrack$).
The ratio of $\ptreco$ to $L(\pttrue)$ (for the appropriate $\theta$, at the appropriate step of the sequential calibration) is shown in (b) and (e), and the ratio is very close to $1$, indicating the learning step is working properly.
The closure of the calibrations at each step of the sequence is shown in (c) and (f) of Figure~\ref{fig:GenNI:ntrack_wtrackmod_seq_LR_CR_scan}.   In both cases, the calibration closes, with an average calibrated response at unity, independent of the features.

\begin{figure}[h!]
  \centering 
  \subfloat[]{\includegraphics[width=0.45\textwidth]{{figures/R_nTrack_scan_preliminary.pdf}}}
  \subfloat[]{\includegraphics[width=0.45\textwidth]{{figures/R_wTrack_mod_scan_preliminary.pdf}}}
  \caption{The dependence of the response on (a) $n_\text{track}$ and (b) $\Rtrack$ in several bins of truth jet $p_\text{T}$.
    }
  \label{fig:GenNI:R_scan}
\end{figure}


\begin{figure}[h!]
  \centering 
  \subfloat[]{\includegraphics[width=0.33\textwidth]{{figures/ntrack_LR_nTrack_scan_preliminary.pdf}}}
  \subfloat[]{\includegraphics[width=0.33\textwidth]{{figures/ntrack_LR_R_nTrack_scan_preliminary.pdf}}}
  \subfloat[]{\includegraphics[width=0.33\textwidth]{{figures/ntrack_CR_nTrack_scan_preliminary.pdf}}}\\
  \subfloat[]{\includegraphics[width=0.33\textwidth]{{figures/ntrack_wtrackmod_seq_LR_wTrack_mod_scan_preliminary.pdf}}}
  \subfloat[]{\includegraphics[width=0.33\textwidth]{{figures/ntrack_wtrackmod_seq_LR_R_wTrack_mod_scan_preliminary.pdf}}}
  \subfloat[]{\includegraphics[width=0.33\textwidth]{{figures/ntrack_wtrackmod_seq_CR_wTrack_mod_scan_preliminary.pdf}}}
  \caption{The dependence of the (a) learned response $L(\pttrue,\theta)/\pttrue$, (b) ratio of $\ptreco$ to learned approximation $L(\pttrue,\theta)$, and (c) calibrated response $C(\ptreco,\theta)/\pttrue$ on $n_\text{track}$ in several bins of truth jet $p_\text{T}$ for $\theta=\{n_\text{track}\}$. Also, the dependence of the (d) learned response $L(\pttrue,\theta)/\pttrue$, (e) ratio of $\ptreco$ to learned approximation $L(\pttrue,\theta)$, and (f) calibrated response $C(\ptreco,\theta)/\pttrue$ on $\Rtrack$ in several bins of truth jet $p_\text{T}$ for $\theta=\{\Rtrack\}$ in sequence after the $n_\text{track}$ correction.
    }
  \label{fig:GenNI:ntrack_wtrackmod_seq_LR_CR_scan}
\end{figure}

Corresponding results for the network trained to simultaneously learn the dependence on $\text{n}_\text{track}$ and $\Rtrack$ are shown in Figure~\ref{fig:GenNI:ntrack_wtrackmod_simul_LR_CR_scan}.
The network is able to learn the dependence on either of the two features in one dimension and the (c) and (f) of Figure~\ref{fig:GenNI:ntrack_wtrackmod_simul_LR_CR_scan} also show that the calibration closes.
The advantage of the simultaneous method is highlighted in Figure~\ref{fig:GenNI:dRdntrack_wTrack_mod}.
After the calibration, in each step of the sequential method, there is still a residual dependence of the calibrated response $\hat{R}$ on $\ntrack$ in individual bins of $\Rtrack$.
This residual dependence is monotonic, and so the single value $d\hat{R}/d\ntrack$ (obtained as the slope when fitting $\hat{R}$ versus $\ntrack$ to a line in bins of $\Rtrack$) parameterizes the remaining residual dependence.
The residual dependence on $\ntrack$ in bins of $\Rtrack$ is nearly the same if the $\text{n}_\text{track}$ or sequential $\text{n}_\text{track}$, $\Rtrack$ calibrations are applied.
However, the slope is zero and independent of $\Rtrack$ when the simultaneous calibration is performed.
Similarly, there is still a residual dependence of $d\hat{R}/d\Rtrack$ on $\ntrack$ if the $\ntrack$ or sequential $\ntrack$, $\Rtrack$ calibrations are applied; this residual dependence goes away with the simultaneous calibration.
Because of this residual dependence, there can be nonclosures in specific regions of the parameter space, despite the calibration closing inclusively overall. In the sequential calibration, large non-closures can be seen in some regions of the parameter space, while the simultaneous calibration almost completely removes these nonclosures.
This comparison illustrates the main benefit of the generalized numerical inversion approach.

\begin{figure}[h!]
  \centering 
  \subfloat[]{\includegraphics[width=0.33\textwidth]{{figures/ntrack_wtrackmod_simulK3U_LR_nTrack_scan_preliminary.pdf}}}
  \subfloat[]{\includegraphics[width=0.33\textwidth]{{figures/ntrack_wtrackmod_simulK3U_LR_R_nTrack_scan_preliminary.pdf}}}
  \subfloat[]{\includegraphics[width=0.33\textwidth]{{figures/ntrack_wtrackmod_simulK3U_CR_nTrack_scan_preliminary.pdf}}}\\
  \subfloat[]{\includegraphics[width=0.33\textwidth]{{figures/ntrack_wtrackmod_simulK3U_LR_wTrack_mod_scan_preliminary.pdf}}}
  \subfloat[]{\includegraphics[width=0.33\textwidth]{{figures/ntrack_wtrackmod_simulK3U_LR_R_wTrack_mod_scan_preliminary.pdf}}}
  \subfloat[]{\includegraphics[width=0.33\textwidth]{{figures/ntrack_wtrackmod_simulK3U_CR_wTrack_mod_scan_preliminary.pdf}}}
  \caption{The dependence of the (a,d) learned response $L(\pttrue,\theta)/\pttrue$, (b,e) ratio of $\ptreco$ to learned approximation $L(\pttrue,\theta)$, and (c,f) calibrated response $C(\ptreco,\theta)/\pttrue$ on (a,b,c) $n_\text{track}$ and (d,e,f) $\Rtrack$, respectively, in several bins of truth jet $p_\text{T}$ for a simultaneous calibration with $\theta=\{n_\text{track},\Rtrack\}$.
    }
  \label{fig:GenNI:ntrack_wtrackmod_simul_LR_CR_scan}
\end{figure}

\begin{figure}[t]
  \centering 
  \subfloat[]{\includegraphics[width=0.45\textwidth]{{figures/dRdntrack_wTrack_mod_ntrack_wtrackmod_preliminary}.pdf}}
  \subfloat[]{\includegraphics[width=0.45\textwidth]{{figures/dRdwTrack_mod_ntrack_ntrack_wtrackmod_preliminary}.pdf}}\\
  \subfloat[]{\includegraphics[width=0.45\textwidth]{{figures/CR_x_compare_ntrack_wtrackmod_all_ntrackg6_wtrackmodg010_preliminary}.pdf}}
  \subfloat[]{\includegraphics[width=0.45\textwidth]{{figures/CR_x_compare_ntrack_wtrackmod_all_ntrackl4_wtrackmodl030_preliminary}.pdf}}\\
  \caption{The dependence of (a) $\frac{d\hat{R}}{dn_\text{track}}$ on $\Rtrack$ and (b) $\frac{d\hat{R}}{d\Rtrack}$ on $\ntrack$ for: a calibration using a network with $\theta=\{n_\text{track}\}$ (circles); a calibration using a network with $\theta=\{\Rtrack\}$ employed sequentially after correcting for $n_\text{track}$ (squares); and a simultaneous calibration using a network with $\theta=\{n_\text{track},\Rtrack\}$ (diamonds).
    Also, the closure as a function of $\pttrue$, highlighting the nonclosure due to this residual dependence in (c) a selection intended to target gluon jets; and (d) a selection intended to target quark jets.
    }
  \label{fig:GenNI:dRdntrack_wTrack_mod}
\end{figure}

As observables sensitive to the quark or gluon nature of a jet, $\text{n}_\text{track}$- and $\Rtrack$-based calibrations ideally reduce the response difference between jet types. Figure~\ref{fig:GenNI:quarkgluon_wtrackmod} shows the difference between the  response for quark and gluon jets as a function of the truth jet $p_\text{T}$ for different calibration methods.  Since gluon jets have a softer constituent $p_\text{T}$ spectrum, their response is lower than for quark jets on average.  Applying any residual correction can be seen to be beneficial in reducing the response difference and the largest reduction is observed for the simultaneous approach.  Reducing the response difference between quark and gluon jets is important for analyses that have an unknown or poorly modeled quark/gluon composition.  The properties of quark and gluon jets can depend on the specific model of jet fragmentation used; therefore, it is also important to check that the improvement in the quark-gluon response difference is robust to these model differences.  In addition to showing the results for \PYTHIA~8, Figure~\ref{fig:GenNI:quarkgluon_wtrackmod} also demonstrates that (without retraining) there are also improvements for \textsc{Herwig}~7. 

%It is also interesting to study the residual response dependence on $\text{n}_\text{track}$ and $\Rtrack$ for a given parton type.  This will show the impact of the calibration on reducing the sensitivity (and thus the systematic uncertainty) of the modeling of jet fragmentation.   Figure~\ref{fig:GenNI:nonclosure_ntrack_quarkgluon} shows the non-closure as a function of $n_\text{track}$ for quark and gluon jets separately, after a sequential or simultaneous calibration.  For quark jets ((c) and (d) of Fig.~\ref{fig:GenNI:nonclosure_ntrack_quarkgluon}) there is a clear reduction in the non-closure from the simultaneous (d) over the sequential calibration (c).   Especially at low $p_\text{T}$, this reduction can reach 20\%.  For gluon jets ((a) and (b)), there is a reduction at high $n_\text{track}$, but not at low $n_\text{track}$.



One step beyond reducing the quark/gluon composition dependence is to reduce the sensitivity to the modeling of the radiation pattern inside a given jet type.  An important consequence of such a reduction could be a smaller systematic uncertainty associated with jet fragmentation modeling.  Figure~\ref{fig:GenNI:respdiff_PythiaHerwig} quantifies this effect by showing the difference in the jet response between \PYTHIA~8 and \textsc{Herwig}~7 for quarks and gluons separately.  It can be seen that the jet response difference between the generators is generally better in the simultaneous calibration method than in the sequential method. 
In particular, in some bins of $\pttrue$, the sequential method makes the difference between the generators worse than not including the second variable, while the simultaneous method retains or slightly improves the difference between the generators.
This could happen if the correlation between the two features changes between the generators in such a way that the sequential calibration effectively undoes the correction of the first feature in the sample the network was not trained on. Another possible effect is that the correlation between the two features stays the same between the generators, but the underlying distribution of one or both of the features in the jets changes. In either case, since the simultaneous method conditions on both features at once, this does not affect the final performance.

\begin{figure}[h!]
  \centering 
  \subfloat[ \PYTHIA~8]{\includegraphics[width=0.45\textwidth]{{figures/quarkgluon_JZ3_Pythia_wtrackmod_ntrack_preliminary}.pdf}}
  \subfloat[\textsc{Herwig}~7 ]{\includegraphics[width=0.45\textwidth]{{figures/quarkgluon_JZ3_Herwig_wtrackmod_ntrack_preliminary}.pdf}}
  \caption{The difference between the response of quarks and gluons as a function of $\pttrue$ for: before any $n_\text{track}$ or $\Rtrack$ correction (open circles); a calibration using a network with $\theta=\{n_\text{track}\}$ (circles); a calibration using a network with  $\theta=\{\Rtrack\}$ sequentially after correcting for $n_\text{track}$ (squares); and a simultaneous calibration using a network with $\theta=\{n_\text{track},\Rtrack\}$ (diamonds).
    }
  \label{fig:GenNI:quarkgluon_wtrackmod}
\end{figure}

\begin{figure}[h!]
  \centering 
  \subfloat[]{\includegraphics[width=0.45\textwidth]{{figures/PythiaHerwig_JZ3_gluon_wtrackmod_ntrack_preliminary}.pdf}}
  \subfloat[]{\includegraphics[width=0.45\textwidth]{{figures/PythiaHerwig_JZ3_quark_wtrackmod_ntrack_preliminary}.pdf}}
  \caption{The difference between the response of jets in Pythia8 and Herwig7 as a function of $\pttrue$ in (a) gluon jets, and (b) quark jets, for: before any $n_\text{track}$ or $ \Rtrack$ correction (open circles); a calibration using a network with $\theta=\{n_\text{track}\}$ (circles); a calibration using a network with  $\theta=\{ \Rtrack\}$ sequentially after correcting for $n_\text{track}$ (squares); and a simultaneous calibration using a network with $\theta=\{n_\text{track}, \Rtrack\}$ (diamonds).
    }
  \label{fig:GenNI:respdiff_PythiaHerwig}
\end{figure}


A final metric for studying the impact of generalized numerical inversion is the jet energy resolution.  One component of the jet energy resolution is due to the spread in the jet energy response for various values of $\theta$.   In the extreme case that there is no spread in $p_\text{T}^\text{reco}$ given $p_\text{T}^\text{true}$ and $\theta$, there will still be an effective resolution resulting from the spread in values over the range of $\theta$.  This contribution to the resolution is reduced with any residual calibration.  However, the calibrated resolution is not only determined by the spread in the response values with $\theta$ and in general need not improve following the calibration.  Figure~\ref{fig:GenNI:stdCR_x_compare_ntrack_wtrackmod} shows both the inclusive (not differential in $\theta$)  closure as well as the inclusive resolution as a function of the truth jet $p_\text{T}$, for different calibration methods.  All methods achieve a similar inclusive closure and as desired, the residual calibration procedures reduce the resolution.  The overall resolution reduction is similar for the sequential and simultaneous approaches, with the simultaneous slightly better at higher $p_\text{T}$ and the sequential slightly better at low $p_\text{T}$.  The difference in the resolutions from the various approaches is small compared to the gain over no residual calibration.



%\begin{figure}[t]
%  \centering 
%  \subfloat[]{\includegraphics[width=0.45\textwidth]{{dRdnTrack_quark_ntrack_wtrackmod_seq}.png}}
%  \subfloat[]{\includegraphics[width=0.45\textwidth]{{dRdnTrack_quark_ntrack_wtrackmod_simulK3U}.png}}
%  \caption{A caption.
%    }
%  \label{fig:GenNI:dRdnTrack_quark_ntrack_wtrackmod_seq}
%\end{figure}



\begin{figure}[t]
  \centering 
  \subfloat[]{\includegraphics[width=0.45\textwidth]{{figures/CR_x_compare_ntrack_wtrackmod_all_preliminary}.pdf}}
  \subfloat[]{\includegraphics[width=0.45\textwidth]{{figures/stdCR_x_compare_ntrack_wtrackmod_all_preliminary}.pdf}}
  \caption{The (a) closure and (b) resolution as a function of $\pttrue$ for: before any $n_\text{track}$ or $\Rtrack$ correction (open circles); a calibration using a network with $\theta=\{n_\text{track}\}$ (circles); a calibration using a network with  $\theta=\{\Rtrack\}$ sequentially after correcting for $n_\text{track}$ (squares); and a simultaneous calibration using a network with $\theta=\{n_\text{track},\Rtrack\}$ (diamonds).
    For the resolution, also shown is the (negative) improvement in quadrature of the resolution for a given calibration with resolution $\sigma^\prime$ to the resolution before any correction $\sigma$.
  }
  \label{fig:GenNI:stdCR_x_compare_ntrack_wtrackmod}
\end{figure}

% All figures and tables should appear before the summary and conclusion.
% The package placeins provides the macro \FloatBarrier to achieve this.
%\FloatBarrier


%-------------------------------------------------------------------------------
\section{Conclusion}
\label{sec:GenNI:conclusion}
%-------------------------------------------------------------------------------

This chapter has presented a study of a regression-based residual jet energy calibration procedure, implemented with neural networks and designed to avoid binning effects and incorporate correlations in the response between various jet features.  This new method can eliminate the residual dependence on one feature after calibrating for a second feature with a strong influence on the response for the first feature.  This can be useful for mitigating the response difference between quark and gluon jets as well as for reducing the residual dependence on the feature for quark or gluon jets separately.  The simultaneous calibration offers similar benefits to the sequential calibration for the jet energy resolution and by construction has no impact on the inclusive closure of the jet calibration.  Generalized numerical inversion is a promising method for the future as more information about jets is included in the calibration procedure.  Further studies are required to incorporate more observables and quantify the potential reduction in the topology dependence and systematic uncertainties of the full approach.
